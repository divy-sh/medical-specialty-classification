{
    "metadata": {
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3",
            "language": "python"
        },
        "language_info": {
            "name": "python",
            "version": "3.11.11",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        },
        "colab": {
            "provenance": [],
            "gpuType": "T4"
        },
        "accelerator": "GPU",
        "kaggle": {
            "accelerator": "nvidiaTeslaT4",
            "dataSources": [
                {
                    "sourceId": 127612,
                    "sourceType": "datasetVersion",
                    "datasetId": 64826
                }
            ],
            "dockerImageVersionId": 31011,
            "isInternetEnabled": true,
            "language": "python",
            "sourceType": "notebook",
            "isGpuEnabled": true
        }
    },
    "nbformat_minor": 4,
    "nbformat": 4,
    "cells": [
        {
            "cell_type": "code",
            "source": "# install required dependencies\n%pip install kagglehub\n%pip install pandas\n%pip install nltk\n%pip install sklearn\n%pip install tensorflow\n%pip install matplotlib\n%pip install tf-keras",
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/"
                },
                "id": "31kgUE4KFLfe",
                "outputId": "b5086d1e-0753-4a02-dc2c-8bfd40c4713a",
                "trusted": true,
                "execution": {
                    "iopub.status.busy": "2025-04-24T08:32:37.880477Z",
                    "iopub.execute_input": "2025-04-24T08:32:37.881059Z",
                    "iopub.status.idle": "2025-04-24T08:36:17.544913Z",
                    "shell.execute_reply.started": "2025-04-24T08:32:37.881038Z",
                    "shell.execute_reply": "2025-04-24T08:36:17.544044Z"
                }
            },
            "outputs": [
                {
                    "name": "stdout",
                    "text": "Requirement already satisfied: kagglehub in /usr/local/lib/python3.11/dist-packages (0.3.11)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from kagglehub) (24.2)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from kagglehub) (6.0.2)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kagglehub) (2.32.3)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from kagglehub) (4.67.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub) (2025.1.31)\nNote: you may need to restart the kernel to use updated packages.\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.3)\nRequirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (1.26.4)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas) (2.4.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.23.2->pandas) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.23.2->pandas) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.23.2->pandas) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.23.2->pandas) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.23.2->pandas) (2024.2.0)\nNote: you may need to restart the kernel to use updated packages.\nRequirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\nRequirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\nRequirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.4.2)\nRequirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\nNote: you may need to restart the kernel to use updated packages.\n\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7f29fe025150>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/sklearn/\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7f29fdcc8090>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/sklearn/\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7f29fdced450>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/sklearn/\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7f29fdd12890>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/sklearn/\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7f29fdda3f50>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/sklearn/\u001b[0m\u001b[33m\n\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement sklearn (from versions: none)\u001b[0m\u001b[31m\n\u001b[0m\u001b[31mERROR: No matching distribution found for sklearn\u001b[0m\u001b[31m\n\u001b[0mNote: you may need to restart the kernel to use updated packages.\nRequirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\nRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\nRequirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\nRequirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\nRequirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\nRequirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\nRequirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\nRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\nRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.20.3)\nRequirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.1.0)\nRequirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\nRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.5.0)\nRequirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.13.1)\nRequirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.70.0)\nRequirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\nRequirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.5.0)\nRequirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.26.4)\nRequirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.12.1)\nRequirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\nRequirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (14.0.0)\nRequirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.8)\nRequirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.14.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<2.1.0,>=1.26.0->tensorflow) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<2.1.0,>=1.26.0->tensorflow) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<2.1.0,>=1.26.0->tensorflow) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<2.1.0,>=1.26.0->tensorflow) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<2.1.0,>=1.26.0->tensorflow) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<2.1.0,>=1.26.0->tensorflow) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\nRequirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2.1.0,>=1.26.0->tensorflow) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2.1.0,>=1.26.0->tensorflow) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<2.1.0,>=1.26.0->tensorflow) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<2.1.0,>=1.26.0->tensorflow) (2024.2.0)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<2.1.0,>=1.26.0->tensorflow) (2024.2.0)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\nNote: you may need to restart the kernel to use updated packages.\nRequirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.7.5)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.56.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\nRequirement already satisfied: numpy<2,>=1.20 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\nRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.1)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<2,>=1.20->matplotlib) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<2,>=1.20->matplotlib) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<2,>=1.20->matplotlib) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<2,>=1.20->matplotlib) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<2,>=1.20->matplotlib) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<2,>=1.20->matplotlib) (2.4.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2,>=1.20->matplotlib) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2,>=1.20->matplotlib) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<2,>=1.20->matplotlib) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<2,>=1.20->matplotlib) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<2,>=1.20->matplotlib) (2024.2.0)\nNote: you may need to restart the kernel to use updated packages.\nRequirement already satisfied: tf-keras in /usr/local/lib/python3.11/dist-packages (2.18.0)\nRequirement already satisfied: tensorflow<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tf-keras) (2.18.0)\nRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (1.4.0)\nRequirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (1.6.3)\nRequirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (25.2.10)\nRequirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (0.6.0)\nRequirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (0.2.0)\nRequirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (18.1.1)\nRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (3.4.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (24.2)\nRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (3.20.3)\nRequirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (2.32.3)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (75.1.0)\nRequirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (1.17.0)\nRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (2.5.0)\nRequirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (4.13.1)\nRequirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (1.17.2)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (1.70.0)\nRequirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (2.18.0)\nRequirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (3.5.0)\nRequirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (1.26.4)\nRequirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (3.12.1)\nRequirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (0.4.1)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (0.37.1)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow<2.19,>=2.18->tf-keras) (0.45.1)\nRequirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow<2.19,>=2.18->tf-keras) (14.0.0)\nRequirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow<2.19,>=2.18->tf-keras) (0.0.8)\nRequirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow<2.19,>=2.18->tf-keras) (0.14.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<2.1.0,>=1.26.0->tensorflow<2.19,>=2.18->tf-keras) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<2.1.0,>=1.26.0->tensorflow<2.19,>=2.18->tf-keras) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<2.1.0,>=1.26.0->tensorflow<2.19,>=2.18->tf-keras) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<2.1.0,>=1.26.0->tensorflow<2.19,>=2.18->tf-keras) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<2.1.0,>=1.26.0->tensorflow<2.19,>=2.18->tf-keras) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<2.1.0,>=1.26.0->tensorflow<2.19,>=2.18->tf-keras) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow<2.19,>=2.18->tf-keras) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow<2.19,>=2.18->tf-keras) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow<2.19,>=2.18->tf-keras) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow<2.19,>=2.18->tf-keras) (2025.1.31)\nRequirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18->tf-keras) (3.7)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18->tf-keras) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18->tf-keras) (3.1.3)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18->tf-keras) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2.1.0,>=1.26.0->tensorflow<2.19,>=2.18->tf-keras) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2.1.0,>=1.26.0->tensorflow<2.19,>=2.18->tf-keras) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<2.1.0,>=1.26.0->tensorflow<2.19,>=2.18->tf-keras) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<2.1.0,>=1.26.0->tensorflow<2.19,>=2.18->tf-keras) (2024.2.0)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow<2.19,>=2.18->tf-keras) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow<2.19,>=2.18->tf-keras) (2.19.1)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<2.1.0,>=1.26.0->tensorflow<2.19,>=2.18->tf-keras) (2024.2.0)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow<2.19,>=2.18->tf-keras) (0.1.2)\nNote: you may need to restart the kernel to use updated packages.\n",
                    "output_type": "stream"
                }
            ],
            "execution_count": 1
        },
        {
            "cell_type": "code",
            "source": "# import all the required dependencies\nimport kagglehub\nimport random\nimport numpy as np\nimport pandas as pd\nimport regex as re\nimport nltk\nfrom nltk.corpus import stopwords, wordnet\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.tokenize import word_tokenize\nfrom multiprocessing import Pool, cpu_count\nimport pickle\n\nnltk.download('stopwords')\nnltk.download('punkt_tab')\nnltk.download('wordnet')",
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/"
                },
                "id": "gQLHDLkJFLfg",
                "outputId": "257f48e1-4237-4c9c-8d78-13789618ad95",
                "trusted": true,
                "execution": {
                    "iopub.status.busy": "2025-04-24T08:47:40.182446Z",
                    "iopub.execute_input": "2025-04-24T08:47:40.183017Z",
                    "iopub.status.idle": "2025-04-24T08:47:40.192989Z",
                    "shell.execute_reply.started": "2025-04-24T08:47:40.182992Z",
                    "shell.execute_reply": "2025-04-24T08:47:40.192305Z"
                }
            },
            "outputs": [
                {
                    "name": "stderr",
                    "text": "[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n[nltk_data] Downloading package punkt_tab to /usr/share/nltk_data...\n[nltk_data]   Package punkt_tab is already up-to-date!\n[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n",
                    "output_type": "stream"
                },
                {
                    "execution_count": 12,
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": "True"
                    },
                    "metadata": {}
                }
            ],
            "execution_count": 12
        },
        {
            "cell_type": "code",
            "source": "# Download dataset\npath = kagglehub.dataset_download(\"tboyle10/medicaltranscriptions\")\nprint(\"Path to dataset files:\", path)\n\ndataset = pd.read_csv(path + \"/mtsamples.csv\")\nprint(\"Head: \", dataset.head)",
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/"
                },
                "id": "fMwqXukyFLfg",
                "outputId": "6dff2be2-4c02-477d-a76c-26bb0182758d",
                "trusted": true,
                "execution": {
                    "iopub.status.busy": "2025-04-24T08:36:53.798011Z",
                    "iopub.execute_input": "2025-04-24T08:36:53.798939Z",
                    "iopub.status.idle": "2025-04-24T08:36:55.795480Z",
                    "shell.execute_reply.started": "2025-04-24T08:36:53.798909Z",
                    "shell.execute_reply": "2025-04-24T08:36:55.794894Z"
                }
            },
            "outputs": [
                {
                    "name": "stdout",
                    "text": "Path to dataset files: /kaggle/input/medicaltranscriptions\nHead:  <bound method NDFrame.head of       Unnamed: 0                                        description  \\\n0              0   A 23-year-old white female presents with comp...   \n1              1           Consult for laparoscopic gastric bypass.   \n2              2           Consult for laparoscopic gastric bypass.   \n3              3                             2-D M-Mode. Doppler.     \n4              4                                 2-D Echocardiogram   \n...          ...                                                ...   \n4994        4994   Patient having severe sinusitis about two to ...   \n4995        4995   This is a 14-month-old baby boy Caucasian who...   \n4996        4996   A female for a complete physical and follow u...   \n4997        4997   Mother states he has been wheezing and coughing.   \n4998        4998   Acute allergic reaction, etiology uncertain, ...   \n\n                medical_specialty                                sample_name  \\\n0            Allergy / Immunology                         Allergic Rhinitis    \n1                      Bariatrics   Laparoscopic Gastric Bypass Consult - 2    \n2                      Bariatrics   Laparoscopic Gastric Bypass Consult - 1    \n3      Cardiovascular / Pulmonary                    2-D Echocardiogram - 1    \n4      Cardiovascular / Pulmonary                    2-D Echocardiogram - 2    \n...                           ...                                        ...   \n4994         Allergy / Immunology                         Chronic Sinusitis    \n4995         Allergy / Immunology      Kawasaki Disease - Discharge Summary    \n4996         Allergy / Immunology                        Followup on Asthma    \n4997         Allergy / Immunology                    Asthma in a 5-year-old    \n4998         Allergy / Immunology                Allergy Evaluation Consult    \n\n                                          transcription  \\\n0     SUBJECTIVE:,  This 23-year-old white female pr...   \n1     PAST MEDICAL HISTORY:, He has difficulty climb...   \n2     HISTORY OF PRESENT ILLNESS: , I have seen ABC ...   \n3     2-D M-MODE: , ,1.  Left atrial enlargement wit...   \n4     1.  The left ventricular cavity size and wall ...   \n...                                                 ...   \n4994  HISTORY:,  I had the pleasure of meeting and e...   \n4995  ADMITTING DIAGNOSIS: , Kawasaki disease.,DISCH...   \n4996  SUBJECTIVE: , This is a 42-year-old white fema...   \n4997  CHIEF COMPLAINT: , This 5-year-old male presen...   \n4998  HISTORY: , A 34-year-old male presents today s...   \n\n                                               keywords  \n0     allergy / immunology, allergic rhinitis, aller...  \n1     bariatrics, laparoscopic gastric bypass, weigh...  \n2     bariatrics, laparoscopic gastric bypass, heart...  \n3     cardiovascular / pulmonary, 2-d m-mode, dopple...  \n4     cardiovascular / pulmonary, 2-d, doppler, echo...  \n...                                                 ...  \n4994                                                NaN  \n4995  allergy / immunology, mucous membranes, conjun...  \n4996                                                NaN  \n4997                                                NaN  \n4998                                                NaN  \n\n[4999 rows x 6 columns]>\n",
                    "output_type": "stream"
                }
            ],
            "execution_count": 3
        },
        {
            "cell_type": "markdown",
            "source": "## Data processing\n\n- We drop every other column except transcription and medical_specialty.\n- We also drop any rows with empty or null transcription or medical_specialty.\n\n- Then we drop all the classes in the excluded specialties list below. We do this as these are general terms and don't specifically map to any specialty.\n- We then merge the classes with large overlaps - e.g. Neurosurgery and neurology, Neurosurgery is a subset of neurology.",
            "metadata": {
                "id": "ZgaYplIzFLfh"
            }
        },
        {
            "cell_type": "code",
            "source": "# Drop rows with missing values in specified columns\ndataset.dropna(subset=['transcription', 'medical_specialty'], inplace=True)\n\n# Keep only relevant columns\ndataset = dataset[['transcription', 'medical_specialty']]\n\n# # Filter medical specialties with at least 30 occurrences\nspecialty_counts = dataset['medical_specialty'].value_counts()\n# valid_specialties = specialty_counts[specialty_counts >= 50].index\n# dataset = dataset[dataset['medical_specialty'].isin(valid_specialties)]\n\n# Strip spaces in 'medical_specialty' column\ndataset['medical_specialty'] = dataset['medical_specialty'].str.strip()\n\n# Remove specific categories\nexcluded_specialties = [\n    'Surgery',\n    'SOAP / Chart / Progress Notes',\n    'Office Notes',\n    'Consult - History and Phy.',\n    'Emergency Room Reports',\n    'Discharge Summary',\n    'Pain Management',\n    'General Medicine',\n    'Radiology',\n]\n\ndataset = dataset[~dataset['medical_specialty'].isin(excluded_specialties)]\n\n# Define category mapping to merge similar categories\ncategory_mapping = {\n    'Neurosurgery': 'Neurology',\n    'Nephrology': 'Urology',\n}\n\n# Apply category mapping\ndataset['medical_specialty'] = dataset['medical_specialty'].replace(category_mapping)\n\n# Display counts for each category\nfor i, (category_name, category) in enumerate(dataset.groupby(\"medical_specialty\")):\n    print(f\"Category {i}: {category_name}: {len(category)}\")",
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/"
                },
                "id": "btKFXrJNFLfm",
                "outputId": "216ab1ce-14f8-4601-f615-a1e814d0875c",
                "trusted": true,
                "execution": {
                    "iopub.status.busy": "2025-04-24T08:36:55.796219Z",
                    "iopub.execute_input": "2025-04-24T08:36:55.796423Z",
                    "iopub.status.idle": "2025-04-24T08:36:55.820620Z",
                    "shell.execute_reply.started": "2025-04-24T08:36:55.796405Z",
                    "shell.execute_reply": "2025-04-24T08:36:55.820066Z"
                }
            },
            "outputs": [
                {
                    "name": "stdout",
                    "text": "Category 0: Allergy / Immunology: 7\nCategory 1: Autopsy: 8\nCategory 2: Bariatrics: 18\nCategory 3: Cardiovascular / Pulmonary: 371\nCategory 4: Chiropractic: 14\nCategory 5: Cosmetic / Plastic Surgery: 27\nCategory 6: Dentistry: 27\nCategory 7: Dermatology: 29\nCategory 8: Diets and Nutritions: 10\nCategory 9: ENT - Otolaryngology: 96\nCategory 10: Endocrinology: 19\nCategory 11: Gastroenterology: 224\nCategory 12: Hematology - Oncology: 90\nCategory 13: Hospice - Palliative Care: 6\nCategory 14: IME-QME-Work Comp etc.: 16\nCategory 15: Lab Medicine - Pathology: 8\nCategory 16: Letters: 23\nCategory 17: Neurology: 317\nCategory 18: Obstetrics / Gynecology: 155\nCategory 19: Ophthalmology: 83\nCategory 20: Orthopedic: 355\nCategory 21: Pediatrics - Neonatal: 70\nCategory 22: Physical Medicine - Rehab: 21\nCategory 23: Podiatry: 47\nCategory 24: Psychiatry / Psychology: 53\nCategory 25: Rheumatology: 10\nCategory 26: Sleep Medicine: 20\nCategory 27: Speech - Language: 9\nCategory 28: Urology: 237\n",
                    "output_type": "stream"
                }
            ],
            "execution_count": 4
        },
        {
            "cell_type": "code",
            "source": "# Helper: Get synonyms from WordNet\ndef get_synonyms(word):\n    synonyms = set()\n    for syn in wordnet.synsets(word):\n        for lemma in syn.lemmas():\n            synonym = lemma.name().replace('_', ' ')\n            if synonym.lower() != word.lower():\n                synonyms.add(synonym)\n    return list(synonyms)\n\n# Synonym Replacement with random n\ndef synonym_replacement(text, n=None):\n    words = word_tokenize(text)\n    new_words = words.copy()\n    eligible_words = list(set([word for word in words if word.isalpha()]))\n    random.shuffle(eligible_words)\n\n    if n is None:\n        n = random.randint(1, min(3, len(eligible_words)))\n\n    num_replaced = 0\n    for word in eligible_words:\n        synonyms = get_synonyms(word)\n        if synonyms:\n            synonym = random.choice(synonyms)\n            new_words = [synonym if w == word else w for w in new_words]\n            num_replaced += 1\n        if num_replaced >= n:\n            break\n    return ' '.join(new_words)\n\n# Word Dropout\ndef word_dropout(text, dropout_prob=0.1):\n    words = word_tokenize(text)\n    new_words = [word for word in words if random.random() > dropout_prob]\n    return ' '.join(new_words) if new_words else text\n\n# Random Swap\ndef random_swap(text, n=1):\n    words = word_tokenize(text)\n    if len(words) < 2:\n        return text\n    for _ in range(n):\n        idx1, idx2 = random.sample(range(len(words)), 2)\n        words[idx1], words[idx2] = words[idx2], words[idx1]\n    return ' '.join(words)\n\n# Apply 1–2 random augmentations\ndef augment_text_randomly(text):\n    aug_functions = [\n        synonym_replacement,\n        word_dropout,\n        random_swap\n    ]\n    num_augs = random.randint(1, 2)\n    selected_augs = random.sample(aug_functions, num_augs)\n    for aug in selected_augs:\n        text = aug(text)\n    return text\n\n# Parallel augmentation per class\ndef augment_class(label_samples_tuple):\n    label, samples_needed, class_samples = label_samples_tuple\n    samples = class_samples.sample(n=samples_needed, replace=True)\n    texts = samples['transcription'].tolist()\n\n    with Pool(cpu_count()) as p:\n        augmented_texts = p.map(augment_text_randomly, texts)\n\n    return pd.DataFrame({\n        'transcription': augmented_texts,\n        'medical_specialty': label\n    })\n\nspecialty_counts = dataset['medical_specialty'].value_counts()\nmax_count = specialty_counts.max()\n\n# Prepare augmentation tasks\ntasks = []\nfor label, count in specialty_counts.items():\n    if count < max_count:\n        samples_needed = max_count - count\n        class_samples = dataset[dataset['medical_specialty'] == label]\n        tasks.append((label, samples_needed, class_samples))\n\n# Run augmentations\naugmented_dfs = [augment_class(task) for task in tasks]\n\n# Combine datasets\naugmented_df = pd.concat(augmented_dfs, ignore_index=True)\ndataset = pd.concat([dataset, augmented_df], ignore_index=True)\n",
            "metadata": {
                "id": "betz_EbrMBtQ",
                "trusted": true,
                "execution": {
                    "iopub.status.busy": "2025-04-24T08:36:55.821327Z",
                    "iopub.execute_input": "2025-04-24T08:36:55.821588Z",
                    "iopub.status.idle": "2025-04-24T08:39:36.091653Z",
                    "shell.execute_reply.started": "2025-04-24T08:36:55.821563Z",
                    "shell.execute_reply": "2025-04-24T08:39:36.090861Z"
                }
            },
            "outputs": [],
            "execution_count": 5
        },
        {
            "cell_type": "markdown",
            "source": "## Data processing\n\n- We clean the text and then tokenize it and then lemmatize all the words in it.",
            "metadata": {
                "id": "FvAv-4CwFLfm"
            }
        },
        {
            "cell_type": "code",
            "source": "from sklearn.model_selection import train_test_split\n\nlemmatizer = None\nstop_words = None\n\ndef init_worker():\n    global lemmatizer, stop_words\n    lemmatizer = WordNetLemmatizer()\n    stop_words = set(stopwords.words('english'))\n\ndef clean_text(text):\n    text = text.strip().lower()\n    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n    tokens = word_tokenize(text)\n    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]\n    return \" \".join(tokens)\n\ndef apply_multiprocessing(series, func, workers=None):\n    with Pool(processes=workers or cpu_count(), initializer=init_worker) as pool:\n        results = pool.map(func, series)\n    return results\n\n# Use multiprocessing to speed it up\ndataset['processed_transcription'] = apply_multiprocessing(dataset['transcription'], clean_text)\n\nX_train, X_test, y_train, y_test = train_test_split(\n    dataset['processed_transcription'], dataset['medical_specialty'], test_size=0.2, random_state=42, stratify=dataset['medical_specialty']\n)",
            "metadata": {
                "id": "HkR5m-76FLfm",
                "trusted": true,
                "execution": {
                    "iopub.status.busy": "2025-04-24T08:39:36.092958Z",
                    "iopub.execute_input": "2025-04-24T08:39:36.093270Z",
                    "iopub.status.idle": "2025-04-24T08:39:54.299028Z",
                    "shell.execute_reply.started": "2025-04-24T08:39:36.093245Z",
                    "shell.execute_reply": "2025-04-24T08:39:54.298194Z"
                }
            },
            "outputs": [],
            "execution_count": 6
        },
        {
            "cell_type": "markdown",
            "source": "## Naive Bayes model",
            "metadata": {
                "id": "ltiKC-3NFLfn"
            }
        },
        {
            "cell_type": "code",
            "source": "from sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import classification_report, accuracy_score\n\npipeline = Pipeline([\n    ('tfidataset', TfidfVectorizer(analyzer='word', stop_words='english',ngram_range=(1,4), max_df=0.8, use_idf=True, smooth_idf=True, max_features=2000)),\n    ('clf', MultinomialNB())  # Train a Naive Bayes classifier\n])\n\n# Train the model\npipeline.fit(X_train, y_train)\n\n# Make predictions\ny_pred = pipeline.predict(X_test)\n\n# Evaluate the model\naccuracy = accuracy_score(y_test, y_pred)\nprint(f'Accuracy: {accuracy:.4f}')\nprint(classification_report(y_test, y_pred))",
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/"
                },
                "id": "Y6Z7gAenFLfn",
                "outputId": "5ef10943-94f9-46df-9cfc-9b93d685d7cb",
                "trusted": true,
                "execution": {
                    "iopub.status.busy": "2025-04-24T08:39:54.300225Z",
                    "iopub.execute_input": "2025-04-24T08:39:54.300521Z",
                    "iopub.status.idle": "2025-04-24T08:40:07.956964Z",
                    "shell.execute_reply.started": "2025-04-24T08:39:54.300478Z",
                    "shell.execute_reply": "2025-04-24T08:40:07.956361Z"
                }
            },
            "outputs": [
                {
                    "name": "stdout",
                    "text": "Accuracy: 0.8467\n                            precision    recall  f1-score   support\n\n      Allergy / Immunology       0.88      1.00      0.94        74\n                   Autopsy       1.00      0.97      0.99        74\n                Bariatrics       0.96      0.91      0.93        74\nCardiovascular / Pulmonary       0.85      0.76      0.80        74\n              Chiropractic       0.69      0.91      0.78        74\nCosmetic / Plastic Surgery       0.53      0.95      0.68        74\n                 Dentistry       0.92      0.95      0.93        75\n               Dermatology       0.97      0.89      0.93        75\n      Diets and Nutritions       0.96      1.00      0.98        74\n      ENT - Otolaryngology       0.87      0.70      0.78        74\n             Endocrinology       0.94      0.96      0.95        75\n          Gastroenterology       0.94      0.66      0.78        74\n     Hematology - Oncology       0.79      0.70      0.74        74\n Hospice - Palliative Care       1.00      1.00      1.00        74\n    IME-QME-Work Comp etc.       0.76      0.77      0.77        75\n  Lab Medicine - Pathology       0.97      1.00      0.99        74\n                   Letters       0.81      0.91      0.85        74\n                 Neurology       0.77      0.41      0.53        74\n   Obstetrics / Gynecology       0.87      0.72      0.79        74\n             Ophthalmology       0.98      0.76      0.86        75\n                Orthopedic       0.75      0.52      0.61        75\n     Pediatrics - Neonatal       0.55      0.61      0.58        74\n Physical Medicine - Rehab       0.90      1.00      0.95        74\n                  Podiatry       0.87      0.92      0.89        74\n   Psychiatry / Psychology       0.80      1.00      0.89        74\n              Rheumatology       0.91      1.00      0.95        74\n            Sleep Medicine       0.91      1.00      0.95        74\n         Speech - Language       0.96      1.00      0.98        74\n                   Urology       0.75      0.59      0.66        74\n\n                  accuracy                           0.85      2152\n                 macro avg       0.86      0.85      0.84      2152\n              weighted avg       0.86      0.85      0.84      2152\n\n",
                    "output_type": "stream"
                }
            ],
            "execution_count": 7
        },
        {
            "cell_type": "markdown",
            "source": "## Logistic Regression Model",
            "metadata": {
                "id": "2kNqSNL5FLfn"
            }
        },
        {
            "cell_type": "code",
            "source": "# Implement Logistic Regression model\nfrom sklearn.linear_model import LogisticRegression\n\n# Create a pipeline with TF-IDF and Logistic Regression\nlr_pipeline = Pipeline([\n    ('tfidf', TfidfVectorizer(analyzer='word', stop_words='english', ngram_range=(1,4),\n                             max_df=0.8, use_idf=True, smooth_idf=True, max_features=2000)),\n    ('clf', LogisticRegression(max_iter=1000, C=1.0, solver='liblinear', multi_class='ovr'))\n])\n\n# Train the model\nlr_pipeline.fit(X_train, y_train)\n\n# Make predictions\nlr_y_pred = lr_pipeline.predict(X_test)\n\n# Evaluate the model\nlr_accuracy = accuracy_score(y_test, lr_y_pred)\nprint(f'Logistic Regression Accuracy: {lr_accuracy:.4f}')\nprint(classification_report(y_test, lr_y_pred))",
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/"
                },
                "id": "IRiLyriuFLfn",
                "outputId": "c1e31cc0-f30d-4cdc-d6b7-6a69154999b0",
                "trusted": true,
                "execution": {
                    "iopub.status.busy": "2025-04-24T08:40:07.957700Z",
                    "iopub.execute_input": "2025-04-24T08:40:07.957910Z",
                    "iopub.status.idle": "2025-04-24T08:40:25.149696Z",
                    "shell.execute_reply.started": "2025-04-24T08:40:07.957890Z",
                    "shell.execute_reply": "2025-04-24T08:40:25.148910Z"
                }
            },
            "outputs": [
                {
                    "name": "stdout",
                    "text": "Logistic Regression Accuracy: 0.9001\n                            precision    recall  f1-score   support\n\n      Allergy / Immunology       0.99      1.00      0.99        74\n                   Autopsy       1.00      0.97      0.99        74\n                Bariatrics       0.97      0.95      0.96        74\nCardiovascular / Pulmonary       0.80      0.88      0.84        74\n              Chiropractic       0.74      0.91      0.82        74\nCosmetic / Plastic Surgery       0.80      0.93      0.86        74\n                 Dentistry       0.95      0.99      0.97        75\n               Dermatology       0.95      0.93      0.94        75\n      Diets and Nutritions       1.00      1.00      1.00        74\n      ENT - Otolaryngology       0.90      0.82      0.86        74\n             Endocrinology       0.95      1.00      0.97        75\n          Gastroenterology       0.95      0.76      0.84        74\n     Hematology - Oncology       0.80      0.88      0.84        74\n Hospice - Palliative Care       1.00      1.00      1.00        74\n    IME-QME-Work Comp etc.       0.78      0.83      0.80        75\n  Lab Medicine - Pathology       0.99      1.00      0.99        74\n                   Letters       0.84      0.85      0.85        74\n                 Neurology       0.74      0.62      0.68        74\n   Obstetrics / Gynecology       0.93      0.88      0.90        74\n             Ophthalmology       0.96      0.87      0.91        75\n                Orthopedic       0.74      0.49      0.59        75\n     Pediatrics - Neonatal       0.86      0.76      0.81        74\n Physical Medicine - Rehab       0.94      1.00      0.97        74\n                  Podiatry       0.86      1.00      0.92        74\n   Psychiatry / Psychology       0.92      0.97      0.95        74\n              Rheumatology       0.99      1.00      0.99        74\n            Sleep Medicine       0.96      1.00      0.98        74\n         Speech - Language       0.97      1.00      0.99        74\n                   Urology       0.84      0.82      0.83        74\n\n                  accuracy                           0.90      2152\n                 macro avg       0.90      0.90      0.90      2152\n              weighted avg       0.90      0.90      0.90      2152\n\n",
                    "output_type": "stream"
                }
            ],
            "execution_count": 8
        },
        {
            "cell_type": "code",
            "source": "import joblib\n# Save Naive Bayes model\njoblib.dump(pipeline, 'naive_bayes_model.pkl')\n\n# Save Logistic Regression model\njoblib.dump(lr_pipeline, 'logistic_regression_model.pkl')",
            "metadata": {
                "trusted": true,
                "execution": {
                    "iopub.status.busy": "2025-04-24T08:41:48.635346Z",
                    "iopub.execute_input": "2025-04-24T08:41:48.635675Z",
                    "iopub.status.idle": "2025-04-24T08:41:56.983224Z",
                    "shell.execute_reply.started": "2025-04-24T08:41:48.635655Z",
                    "shell.execute_reply": "2025-04-24T08:41:56.982662Z"
                }
            },
            "outputs": [
                {
                    "execution_count": 10,
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": "['logistic_regression_model.pkl']"
                    },
                    "metadata": {}
                }
            ],
            "execution_count": 10
        },
        {
            "cell_type": "markdown",
            "source": "## CNN model",
            "metadata": {
                "id": "RT84G_SoFLfn"
            }
        },
        {
            "cell_type": "code",
            "source": "# %%\n# Implement CNN model for text classification\nimport tensorflow as tf\nfrom tensorflow.keras.layers import Dense, Dropout, Embedding, Conv1D, GlobalMaxPooling1D\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom sklearn.preprocessing import LabelEncoder\nimport numpy as np\n\n# Parameters\nmax_features = 50000  # Max vocabulary size\nmaxlen = 2000  # Max sequence length\nembedding_dims = 500  # Embedding dimension\nbatch_size = 128\nepochs = 20\n\n# Convert text to sequences\ntokenizer = Tokenizer(num_words=max_features)\ntokenizer.fit_on_texts(X_train)\nX_train_seq = tokenizer.texts_to_sequences(X_train)\nX_test_seq = tokenizer.texts_to_sequences(X_test)\n\n# Pad sequences to ensure uniform length\nX_train_pad = pad_sequences(X_train_seq, maxlen=maxlen)\nX_test_pad = pad_sequences(X_test_seq, maxlen=maxlen)\n\n# Encode labels\nlabel_encoder = LabelEncoder()\ny_train_encoded = label_encoder.fit_transform(y_train)\ny_test_encoded = label_encoder.transform(y_test)\n\n# Convert to categorical\ny_train_cat = tf.keras.utils.to_categorical(y_train_encoded)\ny_test_cat = tf.keras.utils.to_categorical(y_test_encoded)\n\n# Build the CNN model\nmodel = tf.keras.Sequential([\n    Embedding(max_features, embedding_dims, input_length=maxlen),\n    Dropout(0.2),\n    Conv1D(128, 5, activation='relu'),\n    GlobalMaxPooling1D(),\n    Dense(128, activation='relu'),\n    Dropout(0.2),\n    Dense(y_train_cat.shape[1], activation='softmax')\n])\n\n# Compile the model\nmodel.compile(\n    loss='categorical_crossentropy',\n    optimizer='adam',\n    metrics=['accuracy']\n)\n\n# Print model summary\nmodel.summary()\n\n# Train the model\nhistory = model.fit(\n    X_train_pad,\n    y_train_cat,\n    batch_size=batch_size,\n    epochs=epochs,\n    validation_split=0.2,\n    verbose=1\n)\n\n# Evaluate the model\nloss, cnn_accuracy = model.evaluate(X_test_pad, y_test_cat, verbose=0)\nprint(f'CNN Model Accuracy: {cnn_accuracy:.4f}')\n\n# Get predictions\ny_pred_probs = model.predict(X_test_pad)\ny_pred_classes = np.argmax(y_pred_probs, axis=1)\ny_pred_labels = label_encoder.inverse_transform(y_pred_classes)\n\n# Print classification report\nprint(classification_report(y_test, y_pred_labels))\n\n# Compare with previous models\nprint(f'Naive Bayes Accuracy: {accuracy:.4f}')\nprint(f'Logistic Regression Accuracy: {lr_accuracy:.4f}')\nprint(f'CNN Accuracy: {cnn_accuracy:.4f}')\n\n# Save the CNN model\nmodel.save('cnn_model.h5')\n\n# Save the tokenizer\nwith open('cnn_tokenizer.pickle', 'wb') as handle:\n    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n\n# Save the label encoder\nwith open('cnn_label_encoder.pickle', 'wb') as handle:\n    pickle.dump(label_encoder, handle, protocol=pickle.HIGHEST_PROTOCOL)",
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/",
                    "height": 1000
                },
                "id": "rZnzIi9vFLfn",
                "outputId": "4d2798fc-466e-498c-c1d1-e6dd549a7b80",
                "trusted": true,
                "execution": {
                    "iopub.status.busy": "2025-04-24T08:47:58.771215Z",
                    "iopub.execute_input": "2025-04-24T08:47:58.771906Z",
                    "iopub.status.idle": "2025-04-24T08:52:03.445729Z",
                    "shell.execute_reply.started": "2025-04-24T08:47:58.771883Z",
                    "shell.execute_reply": "2025-04-24T08:52:03.444849Z"
                }
            },
            "outputs": [
                {
                    "name": "stderr",
                    "text": "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n  warnings.warn(\n",
                    "output_type": "stream"
                },
                {
                    "output_type": "display_data",
                    "data": {
                        "text/plain": "\u001b[1mModel: \"sequential_1\"\u001b[0m\n",
                        "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n</pre>\n"
                    },
                    "metadata": {}
                },
                {
                    "output_type": "display_data",
                    "data": {
                        "text/plain": "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)              │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)                  │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)                    │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ global_max_pooling1d_1               │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n│ (\u001b[38;5;33mGlobalMaxPooling1D\u001b[0m)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)                  │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
                        "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                    │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ global_max_pooling1d_1               │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling1D</span>)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n</pre>\n"
                    },
                    "metadata": {}
                },
                {
                    "output_type": "display_data",
                    "data": {
                        "text/plain": "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n",
                        "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"
                    },
                    "metadata": {}
                },
                {
                    "output_type": "display_data",
                    "data": {
                        "text/plain": "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n",
                        "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"
                    },
                    "metadata": {}
                },
                {
                    "output_type": "display_data",
                    "data": {
                        "text/plain": "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n",
                        "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"
                    },
                    "metadata": {}
                },
                {
                    "name": "stdout",
                    "text": "Epoch 1/20\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 257ms/step - accuracy: 0.2030 - loss: 3.1680 - val_accuracy: 0.7184 - val_loss: 1.6763\nEpoch 2/20\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 217ms/step - accuracy: 0.7472 - loss: 1.2488 - val_accuracy: 0.8740 - val_loss: 0.5668\nEpoch 3/20\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 221ms/step - accuracy: 0.9046 - loss: 0.4106 - val_accuracy: 0.8943 - val_loss: 0.4049\nEpoch 4/20\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 218ms/step - accuracy: 0.9371 - loss: 0.2397 - val_accuracy: 0.9077 - val_loss: 0.3737\nEpoch 5/20\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 214ms/step - accuracy: 0.9462 - loss: 0.1822 - val_accuracy: 0.9048 - val_loss: 0.3774\nEpoch 6/20\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 212ms/step - accuracy: 0.9487 - loss: 0.1713 - val_accuracy: 0.8995 - val_loss: 0.3841\nEpoch 7/20\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 212ms/step - accuracy: 0.9511 - loss: 0.1406 - val_accuracy: 0.9030 - val_loss: 0.3991\nEpoch 8/20\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 212ms/step - accuracy: 0.9495 - loss: 0.1493 - val_accuracy: 0.9007 - val_loss: 0.3993\nEpoch 9/20\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 213ms/step - accuracy: 0.9525 - loss: 0.1385 - val_accuracy: 0.9071 - val_loss: 0.3880\nEpoch 10/20\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 214ms/step - accuracy: 0.9548 - loss: 0.1370 - val_accuracy: 0.9053 - val_loss: 0.4084\nEpoch 11/20\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 215ms/step - accuracy: 0.9570 - loss: 0.1205 - val_accuracy: 0.9036 - val_loss: 0.4179\nEpoch 12/20\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 214ms/step - accuracy: 0.9547 - loss: 0.1137 - val_accuracy: 0.9019 - val_loss: 0.4002\nEpoch 13/20\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 214ms/step - accuracy: 0.9628 - loss: 0.0937 - val_accuracy: 0.9042 - val_loss: 0.4108\nEpoch 14/20\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 213ms/step - accuracy: 0.9605 - loss: 0.0987 - val_accuracy: 0.9059 - val_loss: 0.4342\nEpoch 15/20\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 213ms/step - accuracy: 0.9660 - loss: 0.0917 - val_accuracy: 0.8984 - val_loss: 0.4277\nEpoch 16/20\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 214ms/step - accuracy: 0.9664 - loss: 0.0917 - val_accuracy: 0.9036 - val_loss: 0.4411\nEpoch 17/20\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 214ms/step - accuracy: 0.9680 - loss: 0.0808 - val_accuracy: 0.8995 - val_loss: 0.4539\nEpoch 18/20\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 214ms/step - accuracy: 0.9678 - loss: 0.0870 - val_accuracy: 0.8990 - val_loss: 0.4249\nEpoch 19/20\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 214ms/step - accuracy: 0.9633 - loss: 0.0901 - val_accuracy: 0.9042 - val_loss: 0.4420\nEpoch 20/20\n\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 214ms/step - accuracy: 0.9654 - loss: 0.0867 - val_accuracy: 0.9059 - val_loss: 0.4362\nCNN Model Accuracy: 0.8968\n\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step\n                            precision    recall  f1-score   support\n\n      Allergy / Immunology       0.99      1.00      0.99        74\n                   Autopsy       1.00      1.00      1.00        74\n                Bariatrics       0.92      0.97      0.95        74\nCardiovascular / Pulmonary       0.82      0.81      0.82        74\n              Chiropractic       0.85      0.84      0.84        74\nCosmetic / Plastic Surgery       0.86      0.86      0.86        74\n                 Dentistry       0.96      1.00      0.98        75\n               Dermatology       0.94      0.99      0.96        75\n      Diets and Nutritions       1.00      1.00      1.00        74\n      ENT - Otolaryngology       0.94      0.80      0.86        74\n             Endocrinology       0.95      1.00      0.97        75\n          Gastroenterology       0.85      0.82      0.84        74\n     Hematology - Oncology       0.77      0.86      0.82        74\n Hospice - Palliative Care       1.00      0.99      0.99        74\n    IME-QME-Work Comp etc.       0.81      0.76      0.79        75\n  Lab Medicine - Pathology       0.99      1.00      0.99        74\n                   Letters       0.78      0.82      0.80        74\n                 Neurology       0.65      0.64      0.64        74\n   Obstetrics / Gynecology       0.88      0.85      0.86        74\n             Ophthalmology       0.93      0.85      0.89        75\n                Orthopedic       0.66      0.56      0.60        75\n     Pediatrics - Neonatal       0.87      0.80      0.83        74\n Physical Medicine - Rehab       0.95      0.99      0.97        74\n                  Podiatry       0.92      0.97      0.95        74\n   Psychiatry / Psychology       0.95      0.96      0.95        74\n              Rheumatology       0.99      1.00      0.99        74\n            Sleep Medicine       0.96      1.00      0.98        74\n         Speech - Language       0.97      1.00      0.99        74\n                   Urology       0.82      0.86      0.84        74\n\n                  accuracy                           0.90      2152\n                 macro avg       0.90      0.90      0.90      2152\n              weighted avg       0.90      0.90      0.90      2152\n\nNaive Bayes Accuracy: 0.8467\nLogistic Regression Accuracy: 0.9001\nCNN Accuracy: 0.8968\n",
                    "output_type": "stream"
                }
            ],
            "execution_count": 13
        },
        {
            "cell_type": "markdown",
            "source": "## Transformers model",
            "metadata": {
                "id": "UEcqkuNuFLfn"
            }
        },
        {
            "cell_type": "code",
            "source": "from sklearn.preprocessing import LabelEncoder\nfrom transformers import TFAutoModelForSequenceClassification, AutoTokenizer\nfrom tf_keras.optimizers.legacy import Adam\nfrom tf_keras.losses import SparseCategoricalCrossentropy\nfrom sklearn.metrics import classification_report\nimport numpy as np\nfrom tf_keras import mixed_precision\n\nmixed_precision.set_global_policy('mixed_float16')\n\n# Initialize the LabelEncoder\nlabel_encoder = LabelEncoder()\n\ny_train_encoded = label_encoder.fit_transform(y_train)\ny_test_encoded = label_encoder.transform(y_test)\n\n# Parameters\nmax_len = 256  # Max sequence length\nbatch_size = 32\nepochs = 10\n\n# Load a pre-trained BERT model and tokenizer from Hugging Face\nmodel_name = \"medicalai/ClinicalBERT\"\ntokenizer = AutoTokenizer.from_pretrained(model_name)\ntransformer_model = TFAutoModelForSequenceClassification.from_pretrained(model_name, num_labels=len(label_encoder.classes_), from_pt=True)\n\ndef encode_texts(texts):\n    return tokenizer(texts.tolist(), padding=True, truncation=True, max_length=max_len, return_tensors=\"tf\")\n\nX_train_encoded = encode_texts(X_train)\nX_test_encoded = encode_texts(X_test)\n\n# Fine-tune the model\ntransformer_model.compile(optimizer=Adam(learning_rate=2e-5), loss=SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n\n# Train the model\nhistory_transformer = transformer_model.fit(\n    X_train_encoded['input_ids'], y_train_encoded,\n    batch_size=batch_size,\n    epochs=epochs,\n    validation_split=0.2,\n    verbose=1\n)\n\n# Evaluate the model\nloss, transformer_accuracy = transformer_model.evaluate(X_test_encoded['input_ids'], y_test_encoded, verbose=0)\nprint(f'Transformer Model Accuracy: {transformer_accuracy:.4f}')\n\ny_pred_probs_transformer = transformer_model.predict(X_test_encoded['input_ids'])\ny_pred_classes_transformer = np.argmax(y_pred_probs_transformer.logits, axis=1)\ny_pred_labels_transformer = label_encoder.inverse_transform(y_pred_classes_transformer)\n\nprint(classification_report(y_test, y_pred_labels_transformer))\n\n# Compare with previous models\nprint(f'Naive Bayes Accuracy: {accuracy:.4f}')\nprint(f'Logistic Regression Accuracy: {lr_accuracy:.4f}')\nprint(f'CNN Accuracy: {cnn_accuracy:.4f}')\nprint(f'Transformer Accuracy: {transformer_accuracy:.4f}')\n\n# Save the transformer model\ntransformer_model.save_pretrained('transformer_model')\ntokenizer.save_pretrained('transformer_model')\n\n# Save the label encoder\nwith open('transformer_label_encoder.pickle', 'wb') as handle:\n    pickle.dump(label_encoder, handle, protocol=pickle.HIGHEST_PROTOCOL)",
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/",
                    "height": 1000
                },
                "id": "QoysXdbyFLfo",
                "outputId": "2b2a2e65-015d-4245-be22-02482861cf76",
                "trusted": true,
                "execution": {
                    "iopub.status.busy": "2025-04-24T08:52:03.446963Z",
                    "iopub.execute_input": "2025-04-24T08:52:03.447190Z"
                }
            },
            "outputs": [
                {
                    "output_type": "display_data",
                    "data": {
                        "text/plain": "tokenizer_config.json:   0%|          | 0.00/62.0 [00:00<?, ?B/s]",
                        "application/vnd.jupyter.widget-view+json": {
                            "version_major": 2,
                            "version_minor": 0,
                            "model_id": "16b3dff51d8e413d9701c684b5a205b1"
                        }
                    },
                    "metadata": {}
                },
                {
                    "output_type": "display_data",
                    "data": {
                        "text/plain": "config.json:   0%|          | 0.00/466 [00:00<?, ?B/s]",
                        "application/vnd.jupyter.widget-view+json": {
                            "version_major": 2,
                            "version_minor": 0,
                            "model_id": "b41333e641164cf1baa1aba8caa5cbbb"
                        }
                    },
                    "metadata": {}
                },
                {
                    "output_type": "display_data",
                    "data": {
                        "text/plain": "vocab.txt:   0%|          | 0.00/996k [00:00<?, ?B/s]",
                        "application/vnd.jupyter.widget-view+json": {
                            "version_major": 2,
                            "version_minor": 0,
                            "model_id": "b091d1a0811f4f71b137b455d4d1de12"
                        }
                    },
                    "metadata": {}
                },
                {
                    "output_type": "display_data",
                    "data": {
                        "text/plain": "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]",
                        "application/vnd.jupyter.widget-view+json": {
                            "version_major": 2,
                            "version_minor": 0,
                            "model_id": "b9b4011731a4425883412e437e343481"
                        }
                    },
                    "metadata": {}
                },
                {
                    "output_type": "display_data",
                    "data": {
                        "text/plain": "pytorch_model.bin:   0%|          | 0.00/542M [00:00<?, ?B/s]",
                        "application/vnd.jupyter.widget-view+json": {
                            "version_major": 2,
                            "version_minor": 0,
                            "model_id": "7b3523101a8b4f139fdaaac09580381b"
                        }
                    },
                    "metadata": {}
                },
                {
                    "name": "stderr",
                    "text": "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFDistilBertForSequenceClassification: ['vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_transform.weight', 'vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_projector.bias']\n- This IS expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights or buffers of the TF 2.0 model TFDistilBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight', 'classifier.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
                    "output_type": "stream"
                },
                {
                    "name": "stdout",
                    "text": "Epoch 1/10\n216/216 [==============================] - 116s 452ms/step - loss: 2.5216 - accuracy: 0.4815 - val_loss: 1.3186 - val_accuracy: 0.8107\nEpoch 2/10\n216/216 [==============================] - 95s 441ms/step - loss: 0.8140 - accuracy: 0.8776 - val_loss: 0.4537 - val_accuracy: 0.9088\nEpoch 3/10\n216/216 [==============================] - 95s 440ms/step - loss: 0.3874 - accuracy: 0.9139 - val_loss: 0.3404 - val_accuracy: 0.9106\nEpoch 4/10\n216/216 [==============================] - 95s 440ms/step - loss: 0.2782 - accuracy: 0.9264 - val_loss: 0.3340 - val_accuracy: 0.9146\nEpoch 5/10\n216/216 [==============================] - 95s 440ms/step - loss: 0.2359 - accuracy: 0.9294 - val_loss: 0.3089 - val_accuracy: 0.9117\nEpoch 6/10\n216/216 [==============================] - 95s 440ms/step - loss: 0.2052 - accuracy: 0.9368 - val_loss: 0.3198 - val_accuracy: 0.9077\nEpoch 7/10\n216/216 [==============================] - 95s 440ms/step - loss: 0.1840 - accuracy: 0.9377 - val_loss: 0.3057 - val_accuracy: 0.9117\nEpoch 8/10\n216/216 [==============================] - 95s 440ms/step - loss: 0.1740 - accuracy: 0.9373 - val_loss: 0.3191 - val_accuracy: 0.9117\nEpoch 9/10\n216/216 [==============================] - 95s 441ms/step - loss: 0.1613 - accuracy: 0.9419 - val_loss: 0.3089 - val_accuracy: 0.9141\nEpoch 10/10\n202/216 [===========================>..] - ETA: 5s - loss: 0.1541 - accuracy: 0.9431",
                    "output_type": "stream"
                }
            ],
            "execution_count": null
        }
    ]
}