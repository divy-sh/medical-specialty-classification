{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"31kgUE4KFLfe","executionInfo":{"status":"ok","timestamp":1744513378922,"user_tz":240,"elapsed":48287,"user":{"displayName":"divyendu shekhar","userId":"03175873153716445422"}},"outputId":"2e60793d-cb56-4a4c-decb-8a3842d6ce2d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: kagglehub in /usr/local/lib/python3.11/dist-packages (0.3.11)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from kagglehub) (24.2)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from kagglehub) (6.0.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kagglehub) (2.32.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from kagglehub) (4.67.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub) (2025.1.31)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n","Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.4.2)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n","Collecting sklearn\n","  Downloading sklearn-0.0.post12.tar.gz (2.6 kB)\n","  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n","  \n","  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n","  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n","  \u001b[31m╰─>\u001b[0m See above for output.\n","  \n","  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n","\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n","\n","\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n","\u001b[31m╰─>\u001b[0m See above for output.\n","\n","\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n","\u001b[1;36mhint\u001b[0m: See above for details.\n","Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n","Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.4)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.0.1)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.13.1)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.71.0)\n","Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n","Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n","Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.0.2)\n","Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.13.0)\n","Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n","Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n","Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n","Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.14.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.57.0)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n","Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.0.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n","Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n","Requirement already satisfied: tf-keras in /usr/local/lib/python3.11/dist-packages (2.18.0)\n","Requirement already satisfied: tensorflow<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tf-keras) (2.18.0)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (1.6.3)\n","Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (25.2.10)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (0.6.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (0.2.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (18.1.1)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (3.4.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (24.2)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (5.29.4)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (2.32.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (75.2.0)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (1.17.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (3.0.1)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (4.13.1)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (1.17.2)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (1.71.0)\n","Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (2.18.0)\n","Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (3.8.0)\n","Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (2.0.2)\n","Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (3.13.0)\n","Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (0.4.1)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (0.37.1)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow<2.19,>=2.18->tf-keras) (0.45.1)\n","Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow<2.19,>=2.18->tf-keras) (13.9.4)\n","Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow<2.19,>=2.18->tf-keras) (0.0.8)\n","Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow<2.19,>=2.18->tf-keras) (0.14.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow<2.19,>=2.18->tf-keras) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow<2.19,>=2.18->tf-keras) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow<2.19,>=2.18->tf-keras) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow<2.19,>=2.18->tf-keras) (2025.1.31)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18->tf-keras) (3.7)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18->tf-keras) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18->tf-keras) (3.1.3)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18->tf-keras) (3.0.2)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow<2.19,>=2.18->tf-keras) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow<2.19,>=2.18->tf-keras) (2.18.0)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow<2.19,>=2.18->tf-keras) (0.1.2)\n","Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.11/dist-packages (0.13.0)\n","Requirement already satisfied: numpy<3,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (2.0.2)\n","Requirement already satisfied: scipy<2,>=1.10.1 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (1.14.1)\n","Requirement already satisfied: scikit-learn<2,>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (1.6.1)\n","Requirement already satisfied: sklearn-compat<1,>=0.1 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (0.1.3)\n","Requirement already satisfied: joblib<2,>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (1.4.2)\n","Requirement already satisfied: threadpoolctl<4,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (3.6.0)\n"]}],"source":["# install required dependencies\n","%pip install kagglehub\n","%pip install pandas\n","%pip install nltk\n","%pip install sklearn\n","%pip install tensorflow\n","%pip install matplotlib\n","%pip install tf-keras\n","%pip install imbalanced-learn"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gQLHDLkJFLfg","executionInfo":{"status":"ok","timestamp":1744513386898,"user_tz":240,"elapsed":7960,"user":{"displayName":"divyendu shekhar","userId":"03175873153716445422"}},"outputId":"8d68acbe-8d33-4f0e-8b39-f3280702f264"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n","[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":2}],"source":["# import all the required dependencies\n","import kagglehub\n","import pandas as pd\n","import regex as re\n","import nltk\n","from nltk.corpus import stopwords\n","from nltk.stem import WordNetLemmatizer\n","from nltk.tokenize import word_tokenize\n","\n","nltk.download('stopwords')\n","nltk.download('punkt_tab')\n","nltk.download('wordnet')"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fMwqXukyFLfg","executionInfo":{"status":"ok","timestamp":1744513392076,"user_tz":240,"elapsed":5174,"user":{"displayName":"divyendu shekhar","userId":"03175873153716445422"}},"outputId":"2563ddeb-cfdf-4be3-cfe1-fc2ebca9f301"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading from https://www.kaggle.com/api/v1/datasets/download/tboyle10/medicaltranscriptions?dataset_version_number=1...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 4.85M/4.85M [00:00<00:00, 76.7MB/s]"]},{"output_type":"stream","name":"stdout","text":["Extracting files...\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["Path to dataset files: /root/.cache/kagglehub/datasets/tboyle10/medicaltranscriptions/versions/1\n","Head:  <bound method NDFrame.head of       Unnamed: 0                                        description  \\\n","0              0   A 23-year-old white female presents with comp...   \n","1              1           Consult for laparoscopic gastric bypass.   \n","2              2           Consult for laparoscopic gastric bypass.   \n","3              3                             2-D M-Mode. Doppler.     \n","4              4                                 2-D Echocardiogram   \n","...          ...                                                ...   \n","4994        4994   Patient having severe sinusitis about two to ...   \n","4995        4995   This is a 14-month-old baby boy Caucasian who...   \n","4996        4996   A female for a complete physical and follow u...   \n","4997        4997   Mother states he has been wheezing and coughing.   \n","4998        4998   Acute allergic reaction, etiology uncertain, ...   \n","\n","                medical_specialty                                sample_name  \\\n","0            Allergy / Immunology                         Allergic Rhinitis    \n","1                      Bariatrics   Laparoscopic Gastric Bypass Consult - 2    \n","2                      Bariatrics   Laparoscopic Gastric Bypass Consult - 1    \n","3      Cardiovascular / Pulmonary                    2-D Echocardiogram - 1    \n","4      Cardiovascular / Pulmonary                    2-D Echocardiogram - 2    \n","...                           ...                                        ...   \n","4994         Allergy / Immunology                         Chronic Sinusitis    \n","4995         Allergy / Immunology      Kawasaki Disease - Discharge Summary    \n","4996         Allergy / Immunology                        Followup on Asthma    \n","4997         Allergy / Immunology                    Asthma in a 5-year-old    \n","4998         Allergy / Immunology                Allergy Evaluation Consult    \n","\n","                                          transcription  \\\n","0     SUBJECTIVE:,  This 23-year-old white female pr...   \n","1     PAST MEDICAL HISTORY:, He has difficulty climb...   \n","2     HISTORY OF PRESENT ILLNESS: , I have seen ABC ...   \n","3     2-D M-MODE: , ,1.  Left atrial enlargement wit...   \n","4     1.  The left ventricular cavity size and wall ...   \n","...                                                 ...   \n","4994  HISTORY:,  I had the pleasure of meeting and e...   \n","4995  ADMITTING DIAGNOSIS: , Kawasaki disease.,DISCH...   \n","4996  SUBJECTIVE: , This is a 42-year-old white fema...   \n","4997  CHIEF COMPLAINT: , This 5-year-old male presen...   \n","4998  HISTORY: , A 34-year-old male presents today s...   \n","\n","                                               keywords  \n","0     allergy / immunology, allergic rhinitis, aller...  \n","1     bariatrics, laparoscopic gastric bypass, weigh...  \n","2     bariatrics, laparoscopic gastric bypass, heart...  \n","3     cardiovascular / pulmonary, 2-d m-mode, dopple...  \n","4     cardiovascular / pulmonary, 2-d, doppler, echo...  \n","...                                                 ...  \n","4994                                                NaN  \n","4995  allergy / immunology, mucous membranes, conjun...  \n","4996                                                NaN  \n","4997                                                NaN  \n","4998                                                NaN  \n","\n","[4999 rows x 6 columns]>\n"]}],"source":["# Download dataset\n","path = kagglehub.dataset_download(\"tboyle10/medicaltranscriptions\")\n","print(\"Path to dataset files:\", path)\n","\n","dataset = pd.read_csv(path + \"/mtsamples.csv\")\n","print(\"Head: \", dataset.head)"]},{"cell_type":"markdown","metadata":{"id":"ZgaYplIzFLfh"},"source":["## Data processing\n","\n","- We drop every other column except transcription and medical_specialty.\n","- We also drop any rows with empty or null transcription or medical_specialty.\n","\n","- Then we drop all the classes in the excluded specialties list below. We do this as these are general terms and don't specifically map to any specialty.\n","- We then merge the classes with large overlaps - e.g. Neurosurgery and neurology, Neurosurgery is a subset of neurology."]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"btKFXrJNFLfm","executionInfo":{"status":"ok","timestamp":1744513392102,"user_tz":240,"elapsed":21,"user":{"displayName":"divyendu shekhar","userId":"03175873153716445422"}},"outputId":"7192dda1-f34e-440b-ddea-1a4b34a9fe56"},"outputs":[{"output_type":"stream","name":"stdout","text":["Category 0: Cardiovascular / Pulmonary: 371\n","Category 1: ENT - Otolaryngology: 96\n","Category 2: Gastroenterology: 224\n","Category 3: Hematology - Oncology: 90\n","Category 4: Neurology: 317\n","Category 5: Obstetrics / Gynecology: 155\n","Category 6: Ophthalmology: 83\n","Category 7: Orthopedic: 355\n","Category 8: Pediatrics - Neonatal: 70\n","Category 9: Psychiatry / Psychology: 53\n","Category 10: Urology: 237\n"]}],"source":["# Drop rows with missing values in specified columns\n","dataset.dropna(subset=['transcription', 'medical_specialty'], inplace=True)\n","\n","# Keep only relevant columns\n","dataset = dataset[['transcription', 'medical_specialty']]\n","\n","# Filter medical specialties with at least 30 occurrences\n","specialty_counts = dataset['medical_specialty'].value_counts()\n","valid_specialties = specialty_counts[specialty_counts >= 50].index\n","dataset = dataset[dataset['medical_specialty'].isin(valid_specialties)]\n","\n","# Strip spaces in 'medical_specialty' column\n","dataset['medical_specialty'] = dataset['medical_specialty'].str.strip()\n","\n","# Remove specific categories\n","excluded_specialties = [\n","    'Surgery',\n","    'SOAP / Chart / Progress Notes',\n","    'Office Notes',\n","    'Consult - History and Phy.',\n","    'Emergency Room Reports',\n","    'Discharge Summary',\n","    'Pain Management',\n","    'General Medicine',\n","    'Radiology',\n","]\n","\n","dataset = dataset[~dataset['medical_specialty'].isin(excluded_specialties)]\n","\n","# Define category mapping to merge similar categories\n","category_mapping = {\n","    'Neurosurgery': 'Neurology',\n","    'Nephrology': 'Urology',\n","}\n","\n","# Apply category mapping\n","dataset['medical_specialty'] = dataset['medical_specialty'].replace(category_mapping)\n","\n","# Display counts for each category\n","for i, (category_name, category) in enumerate(dataset.groupby(\"medical_specialty\")):\n","    print(f\"Category {i}: {category_name}: {len(category)}\")"]},{"cell_type":"markdown","metadata":{"id":"FvAv-4CwFLfm"},"source":["## Data processing\n","\n","- We clean the text and then tokenize it and then lemmatize all the words in it."]},{"cell_type":"code","execution_count":5,"metadata":{"id":"HkR5m-76FLfm","executionInfo":{"status":"ok","timestamp":1744513487895,"user_tz":240,"elapsed":95790,"user":{"displayName":"divyendu shekhar","userId":"03175873153716445422"}}},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","\n","def clean_text(text):\n","    lemmatizer = WordNetLemmatizer()\n","    text = text.strip()\n","    text = text.lower()\n","    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n","    text = \" \".join([lemmatizer.lemmatize(word) for word in word_tokenize(text) if word not in stopwords.words('english')])\n","    return text\n","\n","dataset['processed_transcription'] = dataset['transcription'].apply(clean_text)\n","\n","X_train, X_test, y_train, y_test = train_test_split(\n","    dataset['processed_transcription'], dataset['medical_specialty'], test_size=0.2, random_state=42, stratify=dataset['medical_specialty']\n",")"]},{"cell_type":"markdown","metadata":{"id":"ltiKC-3NFLfn"},"source":["## Naive Bayes model"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y6Z7gAenFLfn","executionInfo":{"status":"ok","timestamp":1744513492802,"user_tz":240,"elapsed":4915,"user":{"displayName":"divyendu shekhar","userId":"03175873153716445422"}},"outputId":"6d1c424d-bac5-4d3a-854c-c6b2115c9c11"},"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 0.7494\n","                            precision    recall  f1-score   support\n","\n","Cardiovascular / Pulmonary       0.74      0.91      0.82        74\n","      ENT - Otolaryngology       1.00      0.63      0.77        19\n","          Gastroenterology       0.76      0.84      0.80        45\n","     Hematology - Oncology       0.50      0.11      0.18        18\n","                 Neurology       0.65      0.73      0.69        64\n","   Obstetrics / Gynecology       0.90      0.84      0.87        31\n","             Ophthalmology       0.85      0.65      0.73        17\n","                Orthopedic       0.70      0.83      0.76        71\n","     Pediatrics - Neonatal       0.60      0.21      0.32        14\n","   Psychiatry / Psychology       0.71      0.45      0.56        11\n","                   Urology       0.84      0.81      0.83        47\n","\n","                  accuracy                           0.75       411\n","                 macro avg       0.75      0.64      0.67       411\n","              weighted avg       0.75      0.75      0.73       411\n","\n"]}],"source":["from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.naive_bayes import MultinomialNB\n","from sklearn.pipeline import Pipeline\n","from sklearn.metrics import classification_report, accuracy_score\n","\n","pipeline = Pipeline([\n","    ('tfidataset', TfidfVectorizer(analyzer='word', stop_words='english',ngram_range=(1,4), max_df=0.8, use_idf=True, smooth_idf=True, max_features=2000)),\n","    ('clf', MultinomialNB())  # Train a Naive Bayes classifier\n","])\n","\n","# Train the model\n","pipeline.fit(X_train, y_train)\n","\n","# Make predictions\n","y_pred = pipeline.predict(X_test)\n","\n","# Evaluate the model\n","accuracy = accuracy_score(y_test, y_pred)\n","print(f'Accuracy: {accuracy:.4f}')\n","print(classification_report(y_test, y_pred))"]},{"cell_type":"markdown","metadata":{"id":"2kNqSNL5FLfn"},"source":["## Logistic Regression Model"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IRiLyriuFLfn","executionInfo":{"status":"ok","timestamp":1744513497310,"user_tz":240,"elapsed":4504,"user":{"displayName":"divyendu shekhar","userId":"03175873153716445422"}},"outputId":"8dfa29f6-4803-4039-d528-7f71b5bb1b74"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Logistic Regression Accuracy: 0.7786\n","                            precision    recall  f1-score   support\n","\n","Cardiovascular / Pulmonary       0.76      0.88      0.81        74\n","      ENT - Otolaryngology       0.93      0.68      0.79        19\n","          Gastroenterology       0.78      0.84      0.81        45\n","     Hematology - Oncology       0.60      0.17      0.26        18\n","                 Neurology       0.72      0.73      0.73        64\n","   Obstetrics / Gynecology       0.87      0.87      0.87        31\n","             Ophthalmology       0.87      0.76      0.81        17\n","                Orthopedic       0.73      0.90      0.81        71\n","     Pediatrics - Neonatal       0.71      0.36      0.48        14\n","   Psychiatry / Psychology       0.83      0.45      0.59        11\n","                   Urology       0.89      0.85      0.87        47\n","\n","                  accuracy                           0.78       411\n","                 macro avg       0.79      0.68      0.71       411\n","              weighted avg       0.78      0.78      0.77       411\n","\n"]}],"source":["# Implement Logistic Regression model\n","from sklearn.linear_model import LogisticRegression\n","\n","# Create a pipeline with TF-IDF and Logistic Regression\n","lr_pipeline = Pipeline([\n","    ('tfidf', TfidfVectorizer(analyzer='word', stop_words='english', ngram_range=(1,4),\n","                             max_df=0.8, use_idf=True, smooth_idf=True, max_features=2000)),\n","    ('clf', LogisticRegression(max_iter=1000, C=1.0, solver='liblinear', multi_class='ovr'))\n","])\n","\n","# Train the model\n","lr_pipeline.fit(X_train, y_train)\n","\n","# Make predictions\n","lr_y_pred = lr_pipeline.predict(X_test)\n","\n","# Evaluate the model\n","lr_accuracy = accuracy_score(y_test, lr_y_pred)\n","print(f'Logistic Regression Accuracy: {lr_accuracy:.4f}')\n","print(classification_report(y_test, lr_y_pred))"]},{"cell_type":"markdown","metadata":{"id":"RT84G_SoFLfn"},"source":["## CNN model"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"rZnzIi9vFLfn","executionInfo":{"status":"ok","timestamp":1744513574109,"user_tz":240,"elapsed":76796,"user":{"displayName":"divyendu shekhar","userId":"03175873153716445422"}},"outputId":"4a948838-1d16-403b-9367-ead93e9d628b"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["\u001b[1mModel: \"sequential\"\u001b[0m\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n","│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ global_max_pooling1d            │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n","│ (\u001b[38;5;33mGlobalMaxPooling1D\u001b[0m)            │                        │               │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n","└─────────────────────────────────┴────────────────────────┴───────────────┘\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n","│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ global_max_pooling1d            │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling1D</span>)            │                        │               │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n","└─────────────────────────────────┴────────────────────────┴───────────────┘\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n","</pre>\n"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 0.1346 - loss: 2.3488 - val_accuracy: 0.1463 - val_loss: 2.2642\n","Epoch 2/20\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 190ms/step - accuracy: 0.2615 - loss: 2.1171 - val_accuracy: 0.2896 - val_loss: 2.1751\n","Epoch 3/20\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 193ms/step - accuracy: 0.4297 - loss: 1.9313 - val_accuracy: 0.3476 - val_loss: 2.0383\n","Epoch 4/20\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 192ms/step - accuracy: 0.5718 - loss: 1.6889 - val_accuracy: 0.4207 - val_loss: 1.8673\n","Epoch 5/20\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 189ms/step - accuracy: 0.6409 - loss: 1.3426 - val_accuracy: 0.5244 - val_loss: 1.6563\n","Epoch 6/20\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 193ms/step - accuracy: 0.7648 - loss: 0.9314 - val_accuracy: 0.5579 - val_loss: 1.4579\n","Epoch 7/20\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 194ms/step - accuracy: 0.8486 - loss: 0.6537 - val_accuracy: 0.6128 - val_loss: 1.3429\n","Epoch 8/20\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 194ms/step - accuracy: 0.9121 - loss: 0.4154 - val_accuracy: 0.6250 - val_loss: 1.2961\n","Epoch 9/20\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 191ms/step - accuracy: 0.9273 - loss: 0.2793 - val_accuracy: 0.6524 - val_loss: 1.2926\n","Epoch 10/20\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 191ms/step - accuracy: 0.9291 - loss: 0.2188 - val_accuracy: 0.6585 - val_loss: 1.3339\n","Epoch 11/20\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 192ms/step - accuracy: 0.9413 - loss: 0.1828 - val_accuracy: 0.6738 - val_loss: 1.3309\n","Epoch 12/20\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 193ms/step - accuracy: 0.9346 - loss: 0.1852 - val_accuracy: 0.6799 - val_loss: 1.3461\n","Epoch 13/20\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 192ms/step - accuracy: 0.9286 - loss: 0.1718 - val_accuracy: 0.6677 - val_loss: 1.3771\n","Epoch 14/20\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 196ms/step - accuracy: 0.9242 - loss: 0.1605 - val_accuracy: 0.6799 - val_loss: 1.3989\n","Epoch 15/20\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 193ms/step - accuracy: 0.9337 - loss: 0.1667 - val_accuracy: 0.6799 - val_loss: 1.3883\n","Epoch 16/20\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 193ms/step - accuracy: 0.9301 - loss: 0.1574 - val_accuracy: 0.6707 - val_loss: 1.3662\n","Epoch 17/20\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 196ms/step - accuracy: 0.9356 - loss: 0.1727 - val_accuracy: 0.6921 - val_loss: 1.3439\n","Epoch 18/20\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 196ms/step - accuracy: 0.9369 - loss: 0.1630 - val_accuracy: 0.6799 - val_loss: 1.3712\n","Epoch 19/20\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 194ms/step - accuracy: 0.9348 - loss: 0.1578 - val_accuracy: 0.6646 - val_loss: 1.3383\n","Epoch 20/20\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 199ms/step - accuracy: 0.9451 - loss: 0.1471 - val_accuracy: 0.6646 - val_loss: 1.3511\n","CNN Model Accuracy: 0.7421\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step\n","                            precision    recall  f1-score   support\n","\n","Cardiovascular / Pulmonary       0.70      0.88      0.78        74\n","      ENT - Otolaryngology       0.83      0.79      0.81        19\n","          Gastroenterology       0.84      0.71      0.77        45\n","     Hematology - Oncology       0.75      0.17      0.27        18\n","                 Neurology       0.71      0.62      0.67        64\n","   Obstetrics / Gynecology       0.87      0.87      0.87        31\n","             Ophthalmology       0.89      1.00      0.94        17\n","                Orthopedic       0.71      0.85      0.77        71\n","     Pediatrics - Neonatal       0.38      0.21      0.27        14\n","   Psychiatry / Psychology       0.75      0.27      0.40        11\n","                   Urology       0.71      0.85      0.78        47\n","\n","                  accuracy                           0.74       411\n","                 macro avg       0.74      0.66      0.67       411\n","              weighted avg       0.74      0.74      0.73       411\n","\n","Naive Bayes Accuracy: 0.7494\n","Logistic Regression Accuracy: 0.7786\n","CNN Accuracy: 0.7421\n"]}],"source":["# %%\n","# Implement CNN model for text classification\n","import tensorflow as tf\n","from tensorflow.keras.layers import Dense, Dropout, Embedding, Conv1D, GlobalMaxPooling1D\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from sklearn.preprocessing import LabelEncoder\n","import numpy as np\n","\n","# Parameters\n","max_features = 50000  # Max vocabulary size\n","maxlen = 2000  # Max sequence length\n","embedding_dims = 500  # Embedding dimension\n","batch_size = 128\n","epochs = 20\n","\n","# Convert text to sequences\n","tokenizer = Tokenizer(num_words=max_features)\n","tokenizer.fit_on_texts(X_train)\n","X_train_seq = tokenizer.texts_to_sequences(X_train)\n","X_test_seq = tokenizer.texts_to_sequences(X_test)\n","\n","# Pad sequences to ensure uniform length\n","X_train_pad = pad_sequences(X_train_seq, maxlen=maxlen)\n","X_test_pad = pad_sequences(X_test_seq, maxlen=maxlen)\n","\n","# Encode labels\n","label_encoder = LabelEncoder()\n","y_train_encoded = label_encoder.fit_transform(y_train)\n","y_test_encoded = label_encoder.transform(y_test)\n","\n","# Convert to categorical\n","y_train_cat = tf.keras.utils.to_categorical(y_train_encoded)\n","y_test_cat = tf.keras.utils.to_categorical(y_test_encoded)\n","\n","# Build the CNN model\n","model = tf.keras.Sequential([\n","    Embedding(max_features, embedding_dims, input_length=maxlen),\n","    Dropout(0.2),\n","    Conv1D(128, 5, activation='relu'),\n","    GlobalMaxPooling1D(),\n","    Dense(128, activation='relu'),\n","    Dropout(0.2),\n","    Dense(y_train_cat.shape[1], activation='softmax')\n","])\n","\n","# Compile the model\n","model.compile(\n","    loss='categorical_crossentropy',\n","    optimizer='adam',\n","    metrics=['accuracy']\n",")\n","\n","# Print model summary\n","model.summary()\n","\n","# Train the model\n","history = model.fit(\n","    X_train_pad,\n","    y_train_cat,\n","    batch_size=batch_size,\n","    epochs=epochs,\n","    validation_split=0.2,\n","    verbose=1\n",")\n","\n","# Evaluate the model\n","loss, cnn_accuracy = model.evaluate(X_test_pad, y_test_cat, verbose=0)\n","print(f'CNN Model Accuracy: {cnn_accuracy:.4f}')\n","\n","# Get predictions\n","y_pred_probs = model.predict(X_test_pad)\n","y_pred_classes = np.argmax(y_pred_probs, axis=1)\n","y_pred_labels = label_encoder.inverse_transform(y_pred_classes)\n","\n","# Print classification report\n","print(classification_report(y_test, y_pred_labels))\n","\n","# Compare with previous models\n","print(f'Naive Bayes Accuracy: {accuracy:.4f}')\n","print(f'Logistic Regression Accuracy: {lr_accuracy:.4f}')\n","print(f'CNN Accuracy: {cnn_accuracy:.4f}')"]},{"cell_type":"markdown","metadata":{"id":"UEcqkuNuFLfn"},"source":["## Transformers model"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QoysXdbyFLfo","executionInfo":{"status":"ok","timestamp":1744514092921,"user_tz":240,"elapsed":223312,"user":{"displayName":"divyendu shekhar","userId":"03175873153716445422"}},"outputId":"65c47de8-4c29-44e8-940c-d0085f06e388"},"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFDistilBertForSequenceClassification: ['vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight']\n","- This IS expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights or buffers of the TF 2.0 model TFDistilBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","41/41 [==============================] - 26s 457ms/step - loss: 2.2066 - accuracy: 0.2584 - val_loss: 1.9541 - val_accuracy: 0.5793\n","Epoch 2/10\n","41/41 [==============================] - 17s 418ms/step - loss: 1.5147 - accuracy: 0.6524 - val_loss: 1.2323 - val_accuracy: 0.7256\n","Epoch 3/10\n","41/41 [==============================] - 17s 420ms/step - loss: 0.9559 - accuracy: 0.7835 - val_loss: 0.9171 - val_accuracy: 0.7470\n","Epoch 4/10\n","41/41 [==============================] - 17s 422ms/step - loss: 0.6744 - accuracy: 0.8377 - val_loss: 0.7990 - val_accuracy: 0.7805\n","Epoch 5/10\n","41/41 [==============================] - 17s 424ms/step - loss: 0.5145 - accuracy: 0.8788 - val_loss: 0.7288 - val_accuracy: 0.7866\n","Epoch 6/10\n","41/41 [==============================] - 17s 424ms/step - loss: 0.4122 - accuracy: 0.8963 - val_loss: 0.7672 - val_accuracy: 0.7835\n","Epoch 7/10\n","41/41 [==============================] - 19s 457ms/step - loss: 0.3652 - accuracy: 0.9002 - val_loss: 0.7423 - val_accuracy: 0.7805\n","Epoch 8/10\n","41/41 [==============================] - 17s 426ms/step - loss: 0.3082 - accuracy: 0.9002 - val_loss: 0.7147 - val_accuracy: 0.7683\n","Epoch 9/10\n","41/41 [==============================] - 18s 428ms/step - loss: 0.2640 - accuracy: 0.9108 - val_loss: 0.7507 - val_accuracy: 0.7713\n","Epoch 10/10\n","41/41 [==============================] - 19s 459ms/step - loss: 0.2585 - accuracy: 0.9154 - val_loss: 0.8125 - val_accuracy: 0.7744\n","Transformer Model Accuracy: 0.8102\n","13/13 [==============================] - 4s 120ms/step\n","                            precision    recall  f1-score   support\n","\n","Cardiovascular / Pulmonary       0.88      0.88      0.88        74\n","      ENT - Otolaryngology       0.84      0.84      0.84        19\n","          Gastroenterology       0.81      0.96      0.88        45\n","     Hematology - Oncology       0.80      0.22      0.35        18\n","                 Neurology       0.75      0.66      0.70        64\n","   Obstetrics / Gynecology       0.81      0.94      0.87        31\n","             Ophthalmology       0.85      1.00      0.92        17\n","                Orthopedic       0.75      0.82      0.78        71\n","     Pediatrics - Neonatal       0.67      0.57      0.62        14\n","   Psychiatry / Psychology       0.82      0.82      0.82        11\n","                   Urology       0.88      0.89      0.88        47\n","\n","                  accuracy                           0.81       411\n","                 macro avg       0.80      0.78      0.78       411\n","              weighted avg       0.81      0.81      0.80       411\n","\n","Naive Bayes Accuracy: 0.7494\n","Logistic Regression Accuracy: 0.7786\n","CNN Accuracy: 0.7421\n","Transformer Accuracy: 0.8102\n"]}],"source":["from sklearn.preprocessing import LabelEncoder\n","from transformers import TFAutoModelForSequenceClassification, AutoTokenizer\n","from tf_keras.optimizers.legacy import Adam\n","from tf_keras.losses import SparseCategoricalCrossentropy\n","from sklearn.metrics import classification_report\n","import numpy as np\n","from tf_keras import mixed_precision\n","\n","mixed_precision.set_global_policy('mixed_float16')\n","\n","# Initialize the LabelEncoder\n","label_encoder = LabelEncoder()\n","\n","y_train_encoded = label_encoder.fit_transform(y_train)\n","y_test_encoded = label_encoder.transform(y_test)\n","\n","# Parameters\n","max_len = 256  # Max sequence length\n","batch_size = 32\n","epochs = 10\n","\n","# Load a pre-trained BERT model and tokenizer from Hugging Face\n","model_name = \"medicalai/ClinicalBERT\"\n","tokenizer = AutoTokenizer.from_pretrained(model_name)\n","transformer_model = TFAutoModelForSequenceClassification.from_pretrained(model_name, num_labels=len(label_encoder.classes_), from_pt=True)\n","\n","def encode_texts(texts):\n","    return tokenizer(texts.tolist(), padding=True, truncation=True, max_length=max_len, return_tensors=\"tf\")\n","\n","X_train_encoded = encode_texts(X_train)\n","X_test_encoded = encode_texts(X_test)\n","\n","# Fine-tune the model\n","transformer_model.compile(optimizer=Adam(learning_rate=2e-5), loss=SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n","\n","# Train the model\n","history_transformer = transformer_model.fit(\n","    X_train_encoded['input_ids'], y_train_encoded,\n","    batch_size=batch_size,\n","    epochs=epochs,\n","    validation_split=0.2,\n","    verbose=1\n",")\n","\n","# Evaluate the model\n","loss, transformer_accuracy = transformer_model.evaluate(X_test_encoded['input_ids'], y_test_encoded, verbose=0)\n","print(f'Transformer Model Accuracy: {transformer_accuracy:.4f}')\n","\n","y_pred_probs_transformer = transformer_model.predict(X_test_encoded['input_ids'])\n","y_pred_classes_transformer = np.argmax(y_pred_probs_transformer.logits, axis=1)\n","y_pred_labels_transformer = label_encoder.inverse_transform(y_pred_classes_transformer)\n","\n","print(classification_report(y_test, y_pred_labels_transformer))\n","\n","# Compare with previous models\n","print(f'Naive Bayes Accuracy: {accuracy:.4f}')\n","print(f'Logistic Regression Accuracy: {lr_accuracy:.4f}')\n","print(f'CNN Accuracy: {cnn_accuracy:.4f}')\n","print(f'Transformer Accuracy: {transformer_accuracy:.4f}')\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.6"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}