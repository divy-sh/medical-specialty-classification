{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: kagglehub in /Users/divyendu/Library/Python/3.9/lib/python/site-packages (0.3.10)\n",
      "Requirement already satisfied: packaging in /Users/divyendu/Library/Python/3.9/lib/python/site-packages (from kagglehub) (24.2)\n",
      "Requirement already satisfied: pyyaml in /Users/divyendu/Library/Python/3.9/lib/python/site-packages (from kagglehub) (6.0.2)\n",
      "Requirement already satisfied: tqdm in /Users/divyendu/Library/Python/3.9/lib/python/site-packages (from kagglehub) (4.67.1)\n",
      "Requirement already satisfied: requests in /Users/divyendu/Library/Python/3.9/lib/python/site-packages (from kagglehub) (2.32.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/divyendu/Library/Python/3.9/lib/python/site-packages (from requests->kagglehub) (2025.1.31)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/divyendu/Library/Python/3.9/lib/python/site-packages (from requests->kagglehub) (2.3.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/divyendu/Library/Python/3.9/lib/python/site-packages (from requests->kagglehub) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/divyendu/Library/Python/3.9/lib/python/site-packages (from requests->kagglehub) (3.10)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 25.0.1 is available.\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in /Users/divyendu/Library/Python/3.9/lib/python/site-packages (2.2.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/divyendu/Library/Python/3.9/lib/python/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: numpy>=1.22.4 in /Users/divyendu/Library/Python/3.9/lib/python/site-packages (from pandas) (2.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/divyendu/Library/Python/3.9/lib/python/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/divyendu/Library/Python/3.9/lib/python/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/divyendu/Library/Python/3.9/lib/python/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 25.0.1 is available.\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: nltk in /Users/divyendu/Library/Python/3.9/lib/python/site-packages (3.9.1)\n",
      "Requirement already satisfied: joblib in /Users/divyendu/Library/Python/3.9/lib/python/site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: click in /Users/divyendu/Library/Python/3.9/lib/python/site-packages (from nltk) (8.1.8)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/divyendu/Library/Python/3.9/lib/python/site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in /Users/divyendu/Library/Python/3.9/lib/python/site-packages (from nltk) (4.67.1)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 25.0.1 is available.\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: sklearn in /Users/divyendu/Library/Python/3.9/lib/python/site-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in /Users/divyendu/Library/Python/3.9/lib/python/site-packages (from sklearn) (1.6.1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /Users/divyendu/Library/Python/3.9/lib/python/site-packages (from scikit-learn->sklearn) (1.13.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/divyendu/Library/Python/3.9/lib/python/site-packages (from scikit-learn->sklearn) (3.6.0)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /Users/divyendu/Library/Python/3.9/lib/python/site-packages (from scikit-learn->sklearn) (2.0.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/divyendu/Library/Python/3.9/lib/python/site-packages (from scikit-learn->sklearn) (1.4.2)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 25.0.1 is available.\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tensorflow in /Users/divyendu/Library/Python/3.9/lib/python/site-packages (2.19.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/divyendu/Library/Python/3.9/lib/python/site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: tensorboard~=2.19.0 in /Users/divyendu/Library/Python/3.9/lib/python/site-packages (from tensorflow) (2.19.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /Users/divyendu/Library/Python/3.9/lib/python/site-packages (from tensorflow) (0.37.1)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Users/divyendu/Library/Python/3.9/lib/python/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in /Users/divyendu/Library/Python/3.9/lib/python/site-packages (from tensorflow) (3.9.1)\n",
      "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in /Users/divyendu/Library/Python/3.9/lib/python/site-packages (from tensorflow) (2.0.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Users/divyendu/Library/Python/3.9/lib/python/site-packages (from tensorflow) (1.17.2)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /Users/divyendu/Library/Python/3.9/lib/python/site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/divyendu/Library/Python/3.9/lib/python/site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Users/divyendu/Library/Python/3.9/lib/python/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /Users/divyendu/Library/Python/3.9/lib/python/site-packages (from tensorflow) (0.5.1)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/divyendu/Library/Python/3.9/lib/python/site-packages (from tensorflow) (3.0.0)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /Users/divyendu/Library/Python/3.9/lib/python/site-packages (from tensorflow) (3.13.0)\n",
      "Requirement already satisfied: setuptools in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from tensorflow) (58.0.4)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/divyendu/Library/Python/3.9/lib/python/site-packages (from tensorflow) (1.71.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /Users/divyendu/Library/Python/3.9/lib/python/site-packages (from tensorflow) (5.29.4)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /Users/divyendu/Library/Python/3.9/lib/python/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /Users/divyendu/Library/Python/3.9/lib/python/site-packages (from tensorflow) (2.2.1)\n",
      "Requirement already satisfied: packaging in /Users/divyendu/Library/Python/3.9/lib/python/site-packages (from tensorflow) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Users/divyendu/Library/Python/3.9/lib/python/site-packages (from tensorflow) (4.13.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/divyendu/Library/Python/3.9/lib/python/site-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /Users/divyendu/Library/Python/3.9/lib/python/site-packages (from tensorflow) (25.2.10)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from astunparse>=1.6.0->tensorflow) (0.37.0)\n",
      "Requirement already satisfied: namex in /Users/divyendu/Library/Python/3.9/lib/python/site-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in /Users/divyendu/Library/Python/3.9/lib/python/site-packages (from keras>=3.5.0->tensorflow) (0.14.1)\n",
      "Requirement already satisfied: rich in /Users/divyendu/Library/Python/3.9/lib/python/site-packages (from keras>=3.5.0->tensorflow) (14.0.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/divyendu/Library/Python/3.9/lib/python/site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/divyendu/Library/Python/3.9/lib/python/site-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/divyendu/Library/Python/3.9/lib/python/site-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/divyendu/Library/Python/3.9/lib/python/site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/divyendu/Library/Python/3.9/lib/python/site-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Users/divyendu/Library/Python/3.9/lib/python/site-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/divyendu/Library/Python/3.9/lib/python/site-packages (from tensorboard~=2.19.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /Users/divyendu/Library/Python/3.9/lib/python/site-packages (from markdown>=2.6.8->tensorboard~=2.19.0->tensorflow) (8.6.1)\n",
      "Requirement already satisfied: zipp>=3.20 in /Users/divyendu/Library/Python/3.9/lib/python/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.19.0->tensorflow) (3.21.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/divyendu/Library/Python/3.9/lib/python/site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/divyendu/Library/Python/3.9/lib/python/site-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/divyendu/Library/Python/3.9/lib/python/site-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/divyendu/Library/Python/3.9/lib/python/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 25.0.1 is available.\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: matplotlib in /Users/divyendu/Library/Python/3.9/lib/python/site-packages (3.9.4)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/divyendu/Library/Python/3.9/lib/python/site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/divyendu/Library/Python/3.9/lib/python/site-packages (from matplotlib) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/divyendu/Library/Python/3.9/lib/python/site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: numpy>=1.23 in /Users/divyendu/Library/Python/3.9/lib/python/site-packages (from matplotlib) (2.0.2)\n",
      "Requirement already satisfied: pillow>=8 in /Users/divyendu/Library/Python/3.9/lib/python/site-packages (from matplotlib) (11.1.0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /Users/divyendu/Library/Python/3.9/lib/python/site-packages (from matplotlib) (6.5.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/divyendu/Library/Python/3.9/lib/python/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/divyendu/Library/Python/3.9/lib/python/site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/divyendu/Library/Python/3.9/lib/python/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/divyendu/Library/Python/3.9/lib/python/site-packages (from matplotlib) (1.3.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /Users/divyendu/Library/Python/3.9/lib/python/site-packages (from importlib-resources>=3.2.0->matplotlib) (3.21.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/divyendu/Library/Python/3.9/lib/python/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 25.0.1 is available.\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tf-keras in /Users/divyendu/Library/Python/3.9/lib/python/site-packages (2.19.0)\n",
      "Requirement already satisfied: tensorflow<2.20,>=2.19 in /Users/divyendu/Library/Python/3.9/lib/python/site-packages (from tf-keras) (2.19.0)\n",
      "Requirement already satisfied: packaging in /Users/divyendu/Library/Python/3.9/lib/python/site-packages (from tensorflow<2.20,>=2.19->tf-keras) (24.2)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /Users/divyendu/Library/Python/3.9/lib/python/site-packages (from tensorflow<2.20,>=2.19->tf-keras) (18.1.1)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /Users/divyendu/Library/Python/3.9/lib/python/site-packages (from tensorflow<2.20,>=2.19->tf-keras) (0.6.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/divyendu/Library/Python/3.9/lib/python/site-packages (from tensorflow<2.20,>=2.19->tf-keras) (1.71.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /Users/divyendu/Library/Python/3.9/lib/python/site-packages (from tensorflow<2.20,>=2.19->tf-keras) (0.37.1)\n",
      "Requirement already satisfied: setuptools in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from tensorflow<2.20,>=2.19->tf-keras) (58.0.4)\n",
      "Requirement already satisfied: keras>=3.5.0 in /Users/divyendu/Library/Python/3.9/lib/python/site-packages (from tensorflow<2.20,>=2.19->tf-keras) (3.9.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /Users/divyendu/Library/Python/3.9/lib/python/site-packages (from tensorflow<2.20,>=2.19->tf-keras) (2.2.1)\n",
      "Requirement already satisfied: tensorboard~=2.19.0 in /Users/divyendu/Library/Python/3.9/lib/python/site-packages (from tensorflow<2.20,>=2.19->tf-keras) (2.19.0)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /Users/divyendu/Library/Python/3.9/lib/python/site-packages (from tensorflow<2.20,>=2.19->tf-keras) (25.2.10)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Users/divyendu/Library/Python/3.9/lib/python/site-packages (from tensorflow<2.20,>=2.19->tf-keras) (1.17.2)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /Users/divyendu/Library/Python/3.9/lib/python/site-packages (from tensorflow<2.20,>=2.19->tf-keras) (3.13.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Users/divyendu/Library/Python/3.9/lib/python/site-packages (from tensorflow<2.20,>=2.19->tf-keras) (0.2.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/divyendu/Library/Python/3.9/lib/python/site-packages (from tensorflow<2.20,>=2.19->tf-keras) (2.32.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/divyendu/Library/Python/3.9/lib/python/site-packages (from tensorflow<2.20,>=2.19->tf-keras) (3.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Users/divyendu/Library/Python/3.9/lib/python/site-packages (from tensorflow<2.20,>=2.19->tf-keras) (4.13.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/divyendu/Library/Python/3.9/lib/python/site-packages (from tensorflow<2.20,>=2.19->tf-keras) (3.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/divyendu/Library/Python/3.9/lib/python/site-packages (from tensorflow<2.20,>=2.19->tf-keras) (1.17.0)\n",
      "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in /Users/divyendu/Library/Python/3.9/lib/python/site-packages (from tensorflow<2.20,>=2.19->tf-keras) (2.0.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /Users/divyendu/Library/Python/3.9/lib/python/site-packages (from tensorflow<2.20,>=2.19->tf-keras) (5.29.4)\n",
      "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /Users/divyendu/Library/Python/3.9/lib/python/site-packages (from tensorflow<2.20,>=2.19->tf-keras) (0.5.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Users/divyendu/Library/Python/3.9/lib/python/site-packages (from tensorflow<2.20,>=2.19->tf-keras) (1.6.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from astunparse>=1.6.0->tensorflow<2.20,>=2.19->tf-keras) (0.37.0)\n",
      "Requirement already satisfied: optree in /Users/divyendu/Library/Python/3.9/lib/python/site-packages (from keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras) (0.14.1)\n",
      "Requirement already satisfied: namex in /Users/divyendu/Library/Python/3.9/lib/python/site-packages (from keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras) (0.0.8)\n",
      "Requirement already satisfied: rich in /Users/divyendu/Library/Python/3.9/lib/python/site-packages (from keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras) (14.0.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/divyendu/Library/Python/3.9/lib/python/site-packages (from requests<3,>=2.21.0->tensorflow<2.20,>=2.19->tf-keras) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/divyendu/Library/Python/3.9/lib/python/site-packages (from requests<3,>=2.21.0->tensorflow<2.20,>=2.19->tf-keras) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/divyendu/Library/Python/3.9/lib/python/site-packages (from requests<3,>=2.21.0->tensorflow<2.20,>=2.19->tf-keras) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/divyendu/Library/Python/3.9/lib/python/site-packages (from requests<3,>=2.21.0->tensorflow<2.20,>=2.19->tf-keras) (2025.1.31)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Users/divyendu/Library/Python/3.9/lib/python/site-packages (from tensorboard~=2.19.0->tensorflow<2.20,>=2.19->tf-keras) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/divyendu/Library/Python/3.9/lib/python/site-packages (from tensorboard~=2.19.0->tensorflow<2.20,>=2.19->tf-keras) (3.1.3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/divyendu/Library/Python/3.9/lib/python/site-packages (from tensorboard~=2.19.0->tensorflow<2.20,>=2.19->tf-keras) (3.7)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /Users/divyendu/Library/Python/3.9/lib/python/site-packages (from markdown>=2.6.8->tensorboard~=2.19.0->tensorflow<2.20,>=2.19->tf-keras) (8.6.1)\n",
      "Requirement already satisfied: zipp>=3.20 in /Users/divyendu/Library/Python/3.9/lib/python/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.19.0->tensorflow<2.20,>=2.19->tf-keras) (3.21.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/divyendu/Library/Python/3.9/lib/python/site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow<2.20,>=2.19->tf-keras) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/divyendu/Library/Python/3.9/lib/python/site-packages (from rich->keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/divyendu/Library/Python/3.9/lib/python/site-packages (from rich->keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/divyendu/Library/Python/3.9/lib/python/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras) (0.1.2)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 25.0.1 is available.\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# install required dependencies\n",
    "%pip install kagglehub\n",
    "%pip install pandas\n",
    "%pip install nltk\n",
    "%pip install sklearn\n",
    "%pip install tensorflow\n",
    "%pip install matplotlib\n",
    "%pip install tf-keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/divyendu/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /Users/divyendu/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/divyendu/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import all the required dependencies\n",
    "import kagglehub\n",
    "import pandas as pd\n",
    "import regex as re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /Users/divyendu/.cache/kagglehub/datasets/tboyle10/medicaltranscriptions/versions/1\n",
      "Head:  <bound method NDFrame.head of       Unnamed: 0                                        description  \\\n",
      "0              0   A 23-year-old white female presents with comp...   \n",
      "1              1           Consult for laparoscopic gastric bypass.   \n",
      "2              2           Consult for laparoscopic gastric bypass.   \n",
      "3              3                             2-D M-Mode. Doppler.     \n",
      "4              4                                 2-D Echocardiogram   \n",
      "...          ...                                                ...   \n",
      "4994        4994   Patient having severe sinusitis about two to ...   \n",
      "4995        4995   This is a 14-month-old baby boy Caucasian who...   \n",
      "4996        4996   A female for a complete physical and follow u...   \n",
      "4997        4997   Mother states he has been wheezing and coughing.   \n",
      "4998        4998   Acute allergic reaction, etiology uncertain, ...   \n",
      "\n",
      "                medical_specialty                                sample_name  \\\n",
      "0            Allergy / Immunology                         Allergic Rhinitis    \n",
      "1                      Bariatrics   Laparoscopic Gastric Bypass Consult - 2    \n",
      "2                      Bariatrics   Laparoscopic Gastric Bypass Consult - 1    \n",
      "3      Cardiovascular / Pulmonary                    2-D Echocardiogram - 1    \n",
      "4      Cardiovascular / Pulmonary                    2-D Echocardiogram - 2    \n",
      "...                           ...                                        ...   \n",
      "4994         Allergy / Immunology                         Chronic Sinusitis    \n",
      "4995         Allergy / Immunology      Kawasaki Disease - Discharge Summary    \n",
      "4996         Allergy / Immunology                        Followup on Asthma    \n",
      "4997         Allergy / Immunology                    Asthma in a 5-year-old    \n",
      "4998         Allergy / Immunology                Allergy Evaluation Consult    \n",
      "\n",
      "                                          transcription  \\\n",
      "0     SUBJECTIVE:,  This 23-year-old white female pr...   \n",
      "1     PAST MEDICAL HISTORY:, He has difficulty climb...   \n",
      "2     HISTORY OF PRESENT ILLNESS: , I have seen ABC ...   \n",
      "3     2-D M-MODE: , ,1.  Left atrial enlargement wit...   \n",
      "4     1.  The left ventricular cavity size and wall ...   \n",
      "...                                                 ...   \n",
      "4994  HISTORY:,  I had the pleasure of meeting and e...   \n",
      "4995  ADMITTING DIAGNOSIS: , Kawasaki disease.,DISCH...   \n",
      "4996  SUBJECTIVE: , This is a 42-year-old white fema...   \n",
      "4997  CHIEF COMPLAINT: , This 5-year-old male presen...   \n",
      "4998  HISTORY: , A 34-year-old male presents today s...   \n",
      "\n",
      "                                               keywords  \n",
      "0     allergy / immunology, allergic rhinitis, aller...  \n",
      "1     bariatrics, laparoscopic gastric bypass, weigh...  \n",
      "2     bariatrics, laparoscopic gastric bypass, heart...  \n",
      "3     cardiovascular / pulmonary, 2-d m-mode, dopple...  \n",
      "4     cardiovascular / pulmonary, 2-d, doppler, echo...  \n",
      "...                                                 ...  \n",
      "4994                                                NaN  \n",
      "4995  allergy / immunology, mucous membranes, conjun...  \n",
      "4996                                                NaN  \n",
      "4997                                                NaN  \n",
      "4998                                                NaN  \n",
      "\n",
      "[4999 rows x 6 columns]>\n"
     ]
    }
   ],
   "source": [
    "# Download dataset\n",
    "path = kagglehub.dataset_download(\"tboyle10/medicaltranscriptions\")\n",
    "print(\"Path to dataset files:\", path)\n",
    "\n",
    "dataset = pd.read_csv(path + \"/mtsamples.csv\")\n",
    "print(\"Head: \", dataset.head)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data processing\n",
    "\n",
    "- We drop every other column except transcription and medical_specialty.\n",
    "- We also drop any rows with empty or null transcription or medical_specialty.\n",
    "\n",
    "- Then we drop all the classes in the excluded specialties list below. We do this as these are general terms and don't specifically map to any specialty.\n",
    "- We then merge the classes with large overlaps - e.g. Neurosurgery and neurology, Neurosurgery is a subset of neurology."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category 0: Cardiovascular / Pulmonary: 371\n",
      "Category 1: ENT - Otolaryngology: 96\n",
      "Category 2: Gastroenterology: 224\n",
      "Category 3: Hematology - Oncology: 90\n",
      "Category 4: Neurology: 317\n",
      "Category 5: Obstetrics / Gynecology: 155\n",
      "Category 6: Ophthalmology: 83\n",
      "Category 7: Orthopedic: 355\n",
      "Category 8: Pediatrics - Neonatal: 70\n",
      "Category 9: Psychiatry / Psychology: 53\n",
      "Category 10: Radiology: 273\n",
      "Category 11: Urology: 237\n"
     ]
    }
   ],
   "source": [
    "# Drop rows with missing values in specified columns\n",
    "dataset.dropna(subset=['transcription', 'medical_specialty'], inplace=True)\n",
    "\n",
    "# Keep only relevant columns\n",
    "dataset = dataset[['transcription', 'medical_specialty']]\n",
    "\n",
    "# Filter medical specialties with at least 50 occurrences\n",
    "specialty_counts = dataset['medical_specialty'].value_counts()\n",
    "valid_specialties = specialty_counts[specialty_counts >= 50].index\n",
    "dataset = dataset[dataset['medical_specialty'].isin(valid_specialties)]\n",
    "\n",
    "# Strip spaces in 'medical_specialty' column\n",
    "dataset['medical_specialty'] = dataset['medical_specialty'].str.strip()\n",
    "\n",
    "# Remove specific categories\n",
    "excluded_specialties = [\n",
    "    'Surgery',\n",
    "    'SOAP / Chart / Progress Notes',\n",
    "    'Office Notes',\n",
    "    'Consult - History and Phy.',\n",
    "    'Emergency Room Reports',\n",
    "    'Discharge Summary',\n",
    "    'Pain Management',\n",
    "    'General Medicine',\n",
    "]\n",
    "\n",
    "dataset = dataset[~dataset['medical_specialty'].isin(excluded_specialties)]\n",
    "\n",
    "# Define category mapping to merge similar categories\n",
    "category_mapping = {\n",
    "    'Neurosurgery': 'Neurology',\n",
    "    'Nephrology': 'Urology',\n",
    "}\n",
    "\n",
    "# Apply category mapping\n",
    "dataset['medical_specialty'] = dataset['medical_specialty'].replace(category_mapping)\n",
    "\n",
    "# Display counts for each category\n",
    "for i, (category_name, category) in enumerate(dataset.groupby(\"medical_specialty\")):\n",
    "    print(f\"Category {i}: {category_name}: {len(category)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data processing\n",
    "\n",
    "- We clean the text and then tokenize it and then lemmatize all the words in it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def clean_text(text):\n",
    "    lemmatizer = WordNetLemmatizer() \n",
    "    text = text.strip()\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
    "    text = \" \".join([lemmatizer.lemmatize(word) for word in word_tokenize(text) if word not in stopwords.words('english')])\n",
    "    return text\n",
    "\n",
    "dataset['processed_transcription'] = dataset['transcription'].apply(clean_text)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    dataset['transcription'], dataset['medical_specialty'], test_size=0.2, random_state=42, stratify=dataset['medical_specialty']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6774\n",
      "                            precision    recall  f1-score   support\n",
      "\n",
      "Cardiovascular / Pulmonary       0.65      0.85      0.74        74\n",
      "      ENT - Otolaryngology       1.00      0.68      0.81        19\n",
      "          Gastroenterology       0.81      0.76      0.78        45\n",
      "     Hematology - Oncology       0.57      0.22      0.32        18\n",
      "                 Neurology       0.56      0.54      0.55        63\n",
      "   Obstetrics / Gynecology       0.80      0.77      0.79        31\n",
      "             Ophthalmology       0.92      0.71      0.80        17\n",
      "                Orthopedic       0.64      0.80      0.71        71\n",
      "     Pediatrics - Neonatal       0.56      0.36      0.43        14\n",
      "   Psychiatry / Psychology       1.00      0.45      0.62        11\n",
      "                 Radiology       0.46      0.42      0.44        55\n",
      "                   Urology       0.84      0.87      0.85        47\n",
      "\n",
      "                  accuracy                           0.68       465\n",
      "                 macro avg       0.73      0.62      0.65       465\n",
      "              weighted avg       0.68      0.68      0.67       465\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('tfidataset', TfidfVectorizer(analyzer='word', stop_words='english',ngram_range=(1,4), max_df=0.8, use_idf=True, smooth_idf=True, max_features=2000)),\n",
    "    ('clf', MultinomialNB())  # Train a Naive Bayes classifier\n",
    "])\n",
    "\n",
    "# Train the model\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/divyendu/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.6796\n",
      "                            precision    recall  f1-score   support\n",
      "\n",
      "Cardiovascular / Pulmonary       0.66      0.84      0.74        74\n",
      "      ENT - Otolaryngology       0.93      0.74      0.82        19\n",
      "          Gastroenterology       0.73      0.82      0.77        45\n",
      "     Hematology - Oncology       0.50      0.22      0.31        18\n",
      "                 Neurology       0.63      0.54      0.58        63\n",
      "   Obstetrics / Gynecology       0.73      0.77      0.75        31\n",
      "             Ophthalmology       0.88      0.88      0.88        17\n",
      "                Orthopedic       0.71      0.87      0.78        71\n",
      "     Pediatrics - Neonatal       0.75      0.43      0.55        14\n",
      "   Psychiatry / Psychology       1.00      0.45      0.62        11\n",
      "                 Radiology       0.24      0.20      0.22        55\n",
      "                   Urology       0.88      0.89      0.88        47\n",
      "\n",
      "                  accuracy                           0.68       465\n",
      "                 macro avg       0.72      0.64      0.66       465\n",
      "              weighted avg       0.67      0.68      0.67       465\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Implement Logistic Regression model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Create a pipeline with TF-IDF and Logistic Regression\n",
    "lr_pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(analyzer='word', stop_words='english', ngram_range=(1,4), \n",
    "                             max_df=0.8, use_idf=True, smooth_idf=True, max_features=2000)),\n",
    "    ('clf', LogisticRegression(max_iter=1000, C=1.0, solver='liblinear', multi_class='ovr'))\n",
    "])\n",
    "\n",
    "# Train the model\n",
    "lr_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "lr_y_pred = lr_pipeline.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "lr_accuracy = accuracy_score(y_test, lr_y_pred)\n",
    "print(f'Logistic Regression Accuracy: {lr_accuracy:.4f}')\n",
    "print(classification_report(y_test, lr_y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/divyendu/Library/Python/3.9/lib/python/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_12\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_12\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)        │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_max_pooling1d_12         │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling1D</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_13 (\u001b[38;5;33mEmbedding\u001b[0m)        │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_25 (\u001b[38;5;33mDropout\u001b[0m)            │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_13 (\u001b[38;5;33mConv1D\u001b[0m)              │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_max_pooling1d_12         │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalMaxPooling1D\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_24 (\u001b[38;5;33mDense\u001b[0m)                │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_26 (\u001b[38;5;33mDropout\u001b[0m)            │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_25 (\u001b[38;5;33mDense\u001b[0m)                │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 340ms/step - accuracy: 0.1130 - loss: 2.4454 - val_accuracy: 0.1532 - val_loss: 2.3157\n",
      "Epoch 2/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 355ms/step - accuracy: 0.2302 - loss: 2.2272 - val_accuracy: 0.2527 - val_loss: 2.1370\n",
      "Epoch 3/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 427ms/step - accuracy: 0.3589 - loss: 1.9552 - val_accuracy: 0.3737 - val_loss: 1.9131\n",
      "Epoch 4/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 404ms/step - accuracy: 0.5139 - loss: 1.6118 - val_accuracy: 0.4462 - val_loss: 1.6817\n",
      "Epoch 5/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 421ms/step - accuracy: 0.6370 - loss: 1.2626 - val_accuracy: 0.5188 - val_loss: 1.5000\n",
      "Epoch 6/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 461ms/step - accuracy: 0.6931 - loss: 0.9493 - val_accuracy: 0.5161 - val_loss: 1.4352\n",
      "Epoch 7/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 489ms/step - accuracy: 0.7982 - loss: 0.7032 - val_accuracy: 0.5242 - val_loss: 1.4253\n",
      "Epoch 8/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 485ms/step - accuracy: 0.8264 - loss: 0.5571 - val_accuracy: 0.5457 - val_loss: 1.4497\n",
      "Epoch 9/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 482ms/step - accuracy: 0.8554 - loss: 0.4349 - val_accuracy: 0.5538 - val_loss: 1.5258\n",
      "Epoch 10/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 465ms/step - accuracy: 0.8472 - loss: 0.3975 - val_accuracy: 0.5511 - val_loss: 1.5441\n",
      "Epoch 11/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 433ms/step - accuracy: 0.8707 - loss: 0.3541 - val_accuracy: 0.5645 - val_loss: 1.5673\n",
      "Epoch 12/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 425ms/step - accuracy: 0.8632 - loss: 0.3672 - val_accuracy: 0.5618 - val_loss: 1.5847\n",
      "Epoch 13/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 421ms/step - accuracy: 0.8755 - loss: 0.3096 - val_accuracy: 0.5565 - val_loss: 1.6581\n",
      "Epoch 14/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 456ms/step - accuracy: 0.8543 - loss: 0.3487 - val_accuracy: 0.5511 - val_loss: 1.6779\n",
      "Epoch 15/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 454ms/step - accuracy: 0.8495 - loss: 0.3424 - val_accuracy: 0.5753 - val_loss: 1.6613\n",
      "Epoch 16/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 425ms/step - accuracy: 0.8566 - loss: 0.3225 - val_accuracy: 0.5618 - val_loss: 1.6618\n",
      "Epoch 17/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 466ms/step - accuracy: 0.8537 - loss: 0.3218 - val_accuracy: 0.5699 - val_loss: 1.6591\n",
      "Epoch 18/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 444ms/step - accuracy: 0.8654 - loss: 0.3192 - val_accuracy: 0.5672 - val_loss: 1.6711\n",
      "Epoch 19/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 443ms/step - accuracy: 0.8734 - loss: 0.2957 - val_accuracy: 0.5833 - val_loss: 1.6970\n",
      "Epoch 20/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 426ms/step - accuracy: 0.8471 - loss: 0.3110 - val_accuracy: 0.5833 - val_loss: 1.6905\n",
      "CNN Model Accuracy: 0.5419\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step\n",
      "                            precision    recall  f1-score   support\n",
      "\n",
      "Cardiovascular / Pulmonary       0.57      0.64      0.60        74\n",
      "      ENT - Otolaryngology       0.81      0.68      0.74        19\n",
      "          Gastroenterology       0.63      0.64      0.64        45\n",
      "     Hematology - Oncology       0.30      0.17      0.21        18\n",
      "                 Neurology       0.44      0.38      0.41        63\n",
      "   Obstetrics / Gynecology       0.62      0.74      0.68        31\n",
      "             Ophthalmology       0.76      0.94      0.84        17\n",
      "                Orthopedic       0.60      0.63      0.62        71\n",
      "     Pediatrics - Neonatal       0.40      0.29      0.33        14\n",
      "   Psychiatry / Psychology       0.80      0.36      0.50        11\n",
      "                 Radiology       0.14      0.16      0.15        55\n",
      "                   Urology       0.81      0.74      0.78        47\n",
      "\n",
      "                  accuracy                           0.54       465\n",
      "                 macro avg       0.57      0.53      0.54       465\n",
      "              weighted avg       0.55      0.54      0.54       465\n",
      "\n",
      "Naive Bayes Accuracy: 0.6774\n",
      "Logistic Regression Accuracy: 0.6796\n",
      "CNN Accuracy: 0.5419\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# Implement CNN model for text classification\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Dropout, Embedding, Conv1D, GlobalMaxPooling1D\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "\n",
    "# Parameters\n",
    "max_features = 50000  # Max vocabulary size\n",
    "maxlen = 1000  # Max sequence length\n",
    "embedding_dims = 500  # Embedding dimension\n",
    "batch_size = 64\n",
    "epochs = 20\n",
    "\n",
    "# Convert text to sequences\n",
    "tokenizer = Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "# Pad sequences to ensure uniform length\n",
    "X_train_pad = pad_sequences(X_train_seq, maxlen=maxlen)\n",
    "X_test_pad = pad_sequences(X_test_seq, maxlen=maxlen)\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "# Convert to categorical\n",
    "y_train_cat = tf.keras.utils.to_categorical(y_train_encoded)\n",
    "y_test_cat = tf.keras.utils.to_categorical(y_test_encoded)\n",
    "\n",
    "# Build the CNN model\n",
    "model = tf.keras.Sequential([\n",
    "    Embedding(max_features, embedding_dims, input_length=maxlen),\n",
    "    Dropout(0.2),\n",
    "    Conv1D(64, 5, activation='relu'),\n",
    "    GlobalMaxPooling1D(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(y_train_cat.shape[1], activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Print model summary\n",
    "model.summary()\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train_pad, \n",
    "    y_train_cat,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_split=0.2,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "loss, cnn_accuracy = model.evaluate(X_test_pad, y_test_cat, verbose=0)\n",
    "print(f'CNN Model Accuracy: {cnn_accuracy:.4f}')\n",
    "\n",
    "# Get predictions\n",
    "y_pred_probs = model.predict(X_test_pad)\n",
    "y_pred_classes = np.argmax(y_pred_probs, axis=1)\n",
    "y_pred_labels = label_encoder.inverse_transform(y_pred_classes)\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_test, y_pred_labels))\n",
    "\n",
    "# Compare with previous models\n",
    "print(f'Naive Bayes Accuracy: {accuracy:.4f}')\n",
    "print(f'Logistic Regression Accuracy: {lr_accuracy:.4f}')\n",
    "print(f'CNN Accuracy: {cnn_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformers model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from transformers import TFAutoModelForSequenceClassification, AutoTokenizer\n",
    "from tf_keras.optimizers.legacy import Adam\n",
    "from tf_keras.losses import SparseCategoricalCrossentropy\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "# Initialize the LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Assuming y_train and y_test are the labels for the training and testing data\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "# Parameters\n",
    "max_len = 512  # Max sequence length\n",
    "batch_size = 64\n",
    "epochs = 5  # Typically, you might want fewer epochs for transformer models\n",
    "\n",
    "# Load a pre-trained BERT model and tokenizer from Hugging Face\n",
    "model_name = \"bert-base-uncased\"  # You can change this to other models like 'bert-large-uncased' or 'distilbert-base-uncased'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "transformer_model = TFAutoModelForSequenceClassification.from_pretrained(model_name, num_labels=len(label_encoder.classes_))\n",
    "\n",
    "# Tokenize the input texts\n",
    "def encode_texts(texts):\n",
    "    return tokenizer(texts.tolist(), padding=True, truncation=True, max_length=max_len, return_tensors=\"tf\")\n",
    "\n",
    "X_train_encoded = encode_texts(X_train)\n",
    "X_test_encoded = encode_texts(X_test)\n",
    "\n",
    "# Fine-tune the model\n",
    "transformer_model.compile(optimizer=Adam(learning_rate=2e-5), loss=SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history_transformer = transformer_model.fit(\n",
    "    X_train_encoded['input_ids'], y_train_encoded,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_split=0.2,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "loss, transformer_accuracy = transformer_model.evaluate(X_test_encoded['input_ids'], y_test_encoded, verbose=0)\n",
    "print(f'Transformer Model Accuracy: {transformer_accuracy:.4f}')\n",
    "\n",
    "# Get predictions\n",
    "y_pred_probs_transformer = transformer_model.predict(X_test_encoded['input_ids'])\n",
    "y_pred_classes_transformer = np.argmax(y_pred_probs_transformer, axis=1)\n",
    "y_pred_labels_transformer = label_encoder.inverse_transform(y_pred_classes_transformer)\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_test, y_pred_labels_transformer))\n",
    "\n",
    "# Compare with previous models\n",
    "print(f'Naive Bayes Accuracy: {accuracy:.4f}')\n",
    "print(f'Logistic Regression Accuracy: {lr_accuracy:.4f}')\n",
    "print(f'CNN Accuracy: {cnn_accuracy:.4f}')\n",
    "print(f'Transformer Accuracy: {transformer_accuracy:.4f}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
