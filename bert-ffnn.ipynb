{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":127612,"sourceType":"datasetVersion","datasetId":64826}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%pip install kagglehub\n%pip install pandas\n%pip install nltk\n%pip install sklearn\n%pip install tensorflow\n%pip install matplotlib\n%pip install tf-keras","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T19:17:55.694549Z","iopub.execute_input":"2025-04-24T19:17:55.695342Z","iopub.status.idle":"2025-04-24T19:21:08.108995Z","shell.execute_reply.started":"2025-04-24T19:17:55.695301Z","shell.execute_reply":"2025-04-24T19:21:08.107848Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: kagglehub in /usr/local/lib/python3.11/dist-packages (0.3.11)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from kagglehub) (24.2)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from kagglehub) (6.0.2)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kagglehub) (2.32.3)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from kagglehub) (4.67.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub) (2025.1.31)\nNote: you may need to restart the kernel to use updated packages.\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.3)\nRequirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (1.26.4)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas) (2.4.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.23.2->pandas) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.23.2->pandas) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.23.2->pandas) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.23.2->pandas) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.23.2->pandas) (2024.2.0)\nNote: you may need to restart the kernel to use updated packages.\nRequirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\nRequirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\nRequirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.4.2)\nRequirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\nNote: you may need to restart the kernel to use updated packages.\n\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7dace69c6610>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/sklearn/\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7dace6903390>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/sklearn/\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7dace6937650>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/sklearn/\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7dace6b82e10>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/sklearn/\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7dace68fc690>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/sklearn/\u001b[0m\u001b[33m\n\u001b[0mCollecting sklearn\n  Downloading sklearn-0.0.post12.tar.gz (2.6 kB)\n  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n  \n  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n  \u001b[31m╰─>\u001b[0m See above for output.\n  \n  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n\n\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n\u001b[31m╰─>\u001b[0m See above for output.\n\n\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n\u001b[1;36mhint\u001b[0m: See above for details.\nNote: you may need to restart the kernel to use updated packages.\nRequirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\nRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\nRequirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\nRequirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\nRequirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\nRequirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\nRequirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\nRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\nRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.20.3)\nRequirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.1.0)\nRequirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\nRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.5.0)\nRequirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.13.1)\nRequirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.70.0)\nRequirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\nRequirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.5.0)\nRequirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.26.4)\nRequirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.12.1)\nRequirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\nRequirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (14.0.0)\nRequirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.8)\nRequirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.14.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<2.1.0,>=1.26.0->tensorflow) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<2.1.0,>=1.26.0->tensorflow) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<2.1.0,>=1.26.0->tensorflow) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<2.1.0,>=1.26.0->tensorflow) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<2.1.0,>=1.26.0->tensorflow) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<2.1.0,>=1.26.0->tensorflow) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\nRequirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2.1.0,>=1.26.0->tensorflow) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2.1.0,>=1.26.0->tensorflow) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<2.1.0,>=1.26.0->tensorflow) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<2.1.0,>=1.26.0->tensorflow) (2024.2.0)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<2.1.0,>=1.26.0->tensorflow) (2024.2.0)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\nNote: you may need to restart the kernel to use updated packages.\nRequirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.7.5)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.56.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\nRequirement already satisfied: numpy<2,>=1.20 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\nRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.1)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<2,>=1.20->matplotlib) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<2,>=1.20->matplotlib) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<2,>=1.20->matplotlib) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<2,>=1.20->matplotlib) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<2,>=1.20->matplotlib) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<2,>=1.20->matplotlib) (2.4.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2,>=1.20->matplotlib) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2,>=1.20->matplotlib) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<2,>=1.20->matplotlib) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<2,>=1.20->matplotlib) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<2,>=1.20->matplotlib) (2024.2.0)\nNote: you may need to restart the kernel to use updated packages.\nRequirement already satisfied: tf-keras in /usr/local/lib/python3.11/dist-packages (2.18.0)\nRequirement already satisfied: tensorflow<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tf-keras) (2.18.0)\nRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (1.4.0)\nRequirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (1.6.3)\nRequirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (25.2.10)\nRequirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (0.6.0)\nRequirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (0.2.0)\nRequirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (18.1.1)\nRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (3.4.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (24.2)\nRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (3.20.3)\nRequirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (2.32.3)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (75.1.0)\nRequirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (1.17.0)\nRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (2.5.0)\nRequirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (4.13.1)\nRequirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (1.17.2)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (1.70.0)\nRequirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (2.18.0)\nRequirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (3.5.0)\nRequirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (1.26.4)\nRequirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (3.12.1)\nRequirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (0.4.1)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (0.37.1)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow<2.19,>=2.18->tf-keras) (0.45.1)\nRequirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow<2.19,>=2.18->tf-keras) (14.0.0)\nRequirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow<2.19,>=2.18->tf-keras) (0.0.8)\nRequirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow<2.19,>=2.18->tf-keras) (0.14.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<2.1.0,>=1.26.0->tensorflow<2.19,>=2.18->tf-keras) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<2.1.0,>=1.26.0->tensorflow<2.19,>=2.18->tf-keras) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<2.1.0,>=1.26.0->tensorflow<2.19,>=2.18->tf-keras) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<2.1.0,>=1.26.0->tensorflow<2.19,>=2.18->tf-keras) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<2.1.0,>=1.26.0->tensorflow<2.19,>=2.18->tf-keras) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<2.1.0,>=1.26.0->tensorflow<2.19,>=2.18->tf-keras) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow<2.19,>=2.18->tf-keras) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow<2.19,>=2.18->tf-keras) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow<2.19,>=2.18->tf-keras) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow<2.19,>=2.18->tf-keras) (2025.1.31)\nRequirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18->tf-keras) (3.7)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18->tf-keras) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18->tf-keras) (3.1.3)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18->tf-keras) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2.1.0,>=1.26.0->tensorflow<2.19,>=2.18->tf-keras) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2.1.0,>=1.26.0->tensorflow<2.19,>=2.18->tf-keras) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<2.1.0,>=1.26.0->tensorflow<2.19,>=2.18->tf-keras) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<2.1.0,>=1.26.0->tensorflow<2.19,>=2.18->tf-keras) (2024.2.0)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow<2.19,>=2.18->tf-keras) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow<2.19,>=2.18->tf-keras) (2.19.1)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<2.1.0,>=1.26.0->tensorflow<2.19,>=2.18->tf-keras) (2024.2.0)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow<2.19,>=2.18->tf-keras) (0.1.2)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import kagglehub\nimport random\nimport numpy as np\nimport pandas as pd\nimport regex as re\nimport nltk\nfrom nltk.corpus import stopwords, wordnet\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.tokenize import word_tokenize\nfrom multiprocessing import Pool, cpu_count\n\nnltk.download('stopwords')\nnltk.download('punkt_tab')\nnltk.download('wordnet')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T19:21:08.110685Z","iopub.execute_input":"2025-04-24T19:21:08.110931Z","iopub.status.idle":"2025-04-24T19:21:10.122802Z","shell.execute_reply.started":"2025-04-24T19:21:08.110898Z","shell.execute_reply":"2025-04-24T19:21:10.122040Z"}},"outputs":[{"name":"stderr","text":"[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n[nltk_data] Downloading package punkt_tab to /usr/share/nltk_data...\n[nltk_data]   Package punkt_tab is already up-to-date!\n[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n","output_type":"stream"},{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"path = kagglehub.dataset_download(\"tboyle10/medicaltranscriptions\")\nprint(\"Path to dataset files:\", path)\n\ndataset = pd.read_csv(path + \"/mtsamples.csv\")\nprint(\"Head: \", dataset.head)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T19:21:29.920031Z","iopub.execute_input":"2025-04-24T19:21:29.920726Z","iopub.status.idle":"2025-04-24T19:21:35.226124Z","shell.execute_reply.started":"2025-04-24T19:21:29.920697Z","shell.execute_reply":"2025-04-24T19:21:35.225487Z"}},"outputs":[{"name":"stdout","text":"Path to dataset files: /kaggle/input/medicaltranscriptions\nHead:  <bound method NDFrame.head of       Unnamed: 0                                        description  \\\n0              0   A 23-year-old white female presents with comp...   \n1              1           Consult for laparoscopic gastric bypass.   \n2              2           Consult for laparoscopic gastric bypass.   \n3              3                             2-D M-Mode. Doppler.     \n4              4                                 2-D Echocardiogram   \n...          ...                                                ...   \n4994        4994   Patient having severe sinusitis about two to ...   \n4995        4995   This is a 14-month-old baby boy Caucasian who...   \n4996        4996   A female for a complete physical and follow u...   \n4997        4997   Mother states he has been wheezing and coughing.   \n4998        4998   Acute allergic reaction, etiology uncertain, ...   \n\n                medical_specialty                                sample_name  \\\n0            Allergy / Immunology                         Allergic Rhinitis    \n1                      Bariatrics   Laparoscopic Gastric Bypass Consult - 2    \n2                      Bariatrics   Laparoscopic Gastric Bypass Consult - 1    \n3      Cardiovascular / Pulmonary                    2-D Echocardiogram - 1    \n4      Cardiovascular / Pulmonary                    2-D Echocardiogram - 2    \n...                           ...                                        ...   \n4994         Allergy / Immunology                         Chronic Sinusitis    \n4995         Allergy / Immunology      Kawasaki Disease - Discharge Summary    \n4996         Allergy / Immunology                        Followup on Asthma    \n4997         Allergy / Immunology                    Asthma in a 5-year-old    \n4998         Allergy / Immunology                Allergy Evaluation Consult    \n\n                                          transcription  \\\n0     SUBJECTIVE:,  This 23-year-old white female pr...   \n1     PAST MEDICAL HISTORY:, He has difficulty climb...   \n2     HISTORY OF PRESENT ILLNESS: , I have seen ABC ...   \n3     2-D M-MODE: , ,1.  Left atrial enlargement wit...   \n4     1.  The left ventricular cavity size and wall ...   \n...                                                 ...   \n4994  HISTORY:,  I had the pleasure of meeting and e...   \n4995  ADMITTING DIAGNOSIS: , Kawasaki disease.,DISCH...   \n4996  SUBJECTIVE: , This is a 42-year-old white fema...   \n4997  CHIEF COMPLAINT: , This 5-year-old male presen...   \n4998  HISTORY: , A 34-year-old male presents today s...   \n\n                                               keywords  \n0     allergy / immunology, allergic rhinitis, aller...  \n1     bariatrics, laparoscopic gastric bypass, weigh...  \n2     bariatrics, laparoscopic gastric bypass, heart...  \n3     cardiovascular / pulmonary, 2-d m-mode, dopple...  \n4     cardiovascular / pulmonary, 2-d, doppler, echo...  \n...                                                 ...  \n4994                                                NaN  \n4995  allergy / immunology, mucous membranes, conjun...  \n4996                                                NaN  \n4997                                                NaN  \n4998                                                NaN  \n\n[4999 rows x 6 columns]>\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"dataset.dropna(subset=['transcription', 'medical_specialty'], inplace=True)\n\ndataset = dataset[['transcription', 'medical_specialty']]\n\nspecialty_counts = dataset['medical_specialty'].value_counts()\n# valid_specialties = specialty_counts[specialty_counts >= 50].index\n# dataset = dataset[dataset['medical_specialty'].isin(valid_specialties)]\n\ndataset['medical_specialty'] = dataset['medical_specialty'].str.strip()\n\nexcluded_specialties = [\n    'Surgery',\n    'SOAP / Chart / Progress Notes',\n    'Office Notes',\n    'Consult - History and Phy.',\n    'Emergency Room Reports',\n    'Discharge Summary',\n    'Pain Management',\n    'General Medicine',\n    'Radiology',\n]\n\ndataset = dataset[~dataset['medical_specialty'].isin(excluded_specialties)]\n\ncategory_mapping = {\n    'Neurosurgery': 'Neurology',\n    'Nephrology': 'Urology',\n}\n\ndataset['medical_specialty'] = dataset['medical_specialty'].replace(category_mapping)\n\nfor i, (category_name, category) in enumerate(dataset.groupby(\"medical_specialty\")):\n    print(f\"Category {i}: {category_name}: {len(category)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T19:21:49.927616Z","iopub.execute_input":"2025-04-24T19:21:49.927925Z","iopub.status.idle":"2025-04-24T19:21:49.953918Z","shell.execute_reply.started":"2025-04-24T19:21:49.927902Z","shell.execute_reply":"2025-04-24T19:21:49.953210Z"}},"outputs":[{"name":"stdout","text":"Category 0: Allergy / Immunology: 7\nCategory 1: Autopsy: 8\nCategory 2: Bariatrics: 18\nCategory 3: Cardiovascular / Pulmonary: 371\nCategory 4: Chiropractic: 14\nCategory 5: Cosmetic / Plastic Surgery: 27\nCategory 6: Dentistry: 27\nCategory 7: Dermatology: 29\nCategory 8: Diets and Nutritions: 10\nCategory 9: ENT - Otolaryngology: 96\nCategory 10: Endocrinology: 19\nCategory 11: Gastroenterology: 224\nCategory 12: Hematology - Oncology: 90\nCategory 13: Hospice - Palliative Care: 6\nCategory 14: IME-QME-Work Comp etc.: 16\nCategory 15: Lab Medicine - Pathology: 8\nCategory 16: Letters: 23\nCategory 17: Neurology: 317\nCategory 18: Obstetrics / Gynecology: 155\nCategory 19: Ophthalmology: 83\nCategory 20: Orthopedic: 355\nCategory 21: Pediatrics - Neonatal: 70\nCategory 22: Physical Medicine - Rehab: 21\nCategory 23: Podiatry: 47\nCategory 24: Psychiatry / Psychology: 53\nCategory 25: Rheumatology: 10\nCategory 26: Sleep Medicine: 20\nCategory 27: Speech - Language: 9\nCategory 28: Urology: 237\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"def get_synonyms(word):\n    synonyms = set()\n    for syn in wordnet.synsets(word):\n        for lemma in syn.lemmas():\n            synonym = lemma.name().replace('_', ' ')\n            if synonym.lower() != word.lower():\n                synonyms.add(synonym)\n    return list(synonyms)\n\ndef synonym_replacement(text, n=None):\n    words = word_tokenize(text)\n    new_words = words.copy()\n    eligible_words = list(set([word for word in words if word.isalpha()]))\n    random.shuffle(eligible_words)\n\n    if n is None:\n        n = random.randint(1, min(3, len(eligible_words)))\n\n    num_replaced = 0\n    for word in eligible_words:\n        synonyms = get_synonyms(word)\n        if synonyms:\n            synonym = random.choice(synonyms)\n            new_words = [synonym if w == word else w for w in new_words]\n            num_replaced += 1\n        if num_replaced >= n:\n            break\n    return ' '.join(new_words)\n\ndef word_dropout(text, dropout_prob=0.1):\n    words = word_tokenize(text)\n    new_words = [word for word in words if random.random() > dropout_prob]\n    return ' '.join(new_words) if new_words else text\n\ndef random_swap(text, n=1):\n    words = word_tokenize(text)\n    if len(words) < 2:\n        return text\n    for _ in range(n):\n        idx1, idx2 = random.sample(range(len(words)), 2)\n        words[idx1], words[idx2] = words[idx2], words[idx1]\n    return ' '.join(words)\n\ndef augment_text_randomly(text):\n    aug_functions = [\n        synonym_replacement,\n        word_dropout,\n        random_swap\n    ]\n    num_augs = random.randint(1, 2)\n    selected_augs = random.sample(aug_functions, num_augs)\n    for aug in selected_augs:\n        text = aug(text)\n    return text\n\ndef augment_class(label_samples_tuple):\n    label, samples_needed, class_samples = label_samples_tuple\n    samples = class_samples.sample(n=samples_needed, replace=True)\n    texts = samples['transcription'].tolist()\n\n    with Pool(cpu_count()) as p:\n        augmented_texts = p.map(augment_text_randomly, texts)\n\n    return pd.DataFrame({\n        'transcription': augmented_texts,\n        'medical_specialty': label\n    })\n\nspecialty_counts = dataset['medical_specialty'].value_counts()\nmax_count = specialty_counts.max()\n\ntasks = []\nfor label, count in specialty_counts.items():\n    if count < max_count:\n        samples_needed = max_count - count\n        class_samples = dataset[dataset['medical_specialty'] == label]\n        tasks.append((label, samples_needed, class_samples))\n\naugmented_dfs = [augment_class(task) for task in tasks]\n\naugmented_df = pd.concat(augmented_dfs, ignore_index=True)\ndataset = pd.concat([dataset, augmented_df], ignore_index=True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T19:22:03.719386Z","iopub.execute_input":"2025-04-24T19:22:03.720047Z","iopub.status.idle":"2025-04-24T19:24:53.773978Z","shell.execute_reply.started":"2025-04-24T19:22:03.720023Z","shell.execute_reply":"2025-04-24T19:24:53.773109Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nlemmatizer = None\nstop_words = None\n\ndef init_worker():\n    global lemmatizer, stop_words\n    lemmatizer = WordNetLemmatizer()\n    stop_words = set(stopwords.words('english'))\n\ndef clean_text(text):\n    text = text.strip().lower()\n    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n    tokens = word_tokenize(text)\n    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]\n    return \" \".join(tokens)\n\ndef apply_multiprocessing(series, func, workers=None):\n    with Pool(processes=workers or cpu_count(), initializer=init_worker) as pool:\n        results = pool.map(func, series)\n    return results\n\n# Use multiprocessing to speed it up\ndataset['processed_transcription'] = apply_multiprocessing(dataset['transcription'], clean_text)\n\nX_train, X_test, y_train, y_test = train_test_split(\n    dataset['processed_transcription'], dataset['medical_specialty'], test_size=0.2, random_state=42, stratify=dataset['medical_specialty']\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T19:26:06.577728Z","iopub.execute_input":"2025-04-24T19:26:06.578463Z","iopub.status.idle":"2025-04-24T19:26:26.245975Z","shell.execute_reply.started":"2025-04-24T19:26:06.578433Z","shell.execute_reply":"2025-04-24T19:26:26.245208Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"import torch\nfrom transformers import BertTokenizer, BertModel\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout\nfrom tensorflow.keras.utils import to_categorical\nimport numpy as np\nfrom tqdm import tqdm\n\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\nbert = BertModel.from_pretrained('bert-base-uncased')\n\ndef get_bert_embeddings(texts):\n    embeddings = []\n    for text in tqdm(texts):\n        inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=256)\n        with torch.no_grad():\n            outputs = bert(**inputs)\n        cls_embedding = outputs.last_hidden_state[:, 0, :].squeeze().numpy()\n        embeddings.append(cls_embedding)\n    return np.array(embeddings)\n\nlabel_encoder = LabelEncoder()\n\ny_encoded = label_encoder.fit_transform(y_train)\n\nX_train_bert = get_bert_embeddings(X_train)\nX_test_bert = get_bert_embeddings(X_test)\n\ny_train_cat = to_categorical(y_encoded)\ny_test_encoded_cat = label_encoder.transform(y_test)\ny_test_cat = to_categorical(y_test_encoded_cat)\n\nmodel = Sequential()\nmodel.add(Dense(256, activation='relu', input_shape=(768,)))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(len(label_encoder.classes_), activation='softmax'))\n\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n\nmodel.fit(X_train_bert, y_train_cat, epochs=20, batch_size=32, validation_split=0.2)\n\ny_pred_probs = model.predict(X_test_bert)\ny_pred = np.argmax(y_pred_probs, axis=1)\n\nfrom sklearn.metrics import classification_report\nprint(classification_report(y_test_encoded_cat, y_pred, digits=4))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T19:26:38.653462Z","iopub.execute_input":"2025-04-24T19:26:38.654244Z","iopub.status.idle":"2025-04-24T20:11:26.679011Z","shell.execute_reply.started":"2025-04-24T19:26:38.654215Z","shell.execute_reply":"2025-04-24T20:11:26.678183Z"}},"outputs":[{"name":"stderr","text":"2025-04-24 19:26:51.614880: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1745522811.811727      31 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1745522811.870743      31 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"edebeaa7a47c4da99a083fb6d0f6ead0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a62056d3b979409091f32fefa1794ee4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"389aa1fd138d4b77841ce2049fb4ed80"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"41fef0a61081452983b6fbb0a289980a"}},"metadata":{}},{"name":"stderr","text":"Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"16da772270f84eb3b298d9a3e66c45b8"}},"metadata":{}},{"name":"stderr","text":"100%|██████████| 8607/8607 [35:21<00:00,  4.06it/s]\n100%|██████████| 2152/2152 [08:41<00:00,  4.12it/s]\n/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\nI0000 00:00:1745525471.200752      31 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\nI0000 00:00:1745525471.201531      31 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13942 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/20\n","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1745525473.998688     343 service.cc:148] XLA service 0x7a23a00066c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1745525473.999340     343 service.cc:156]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\nI0000 00:00:1745525473.999361     343 service.cc:156]   StreamExecutor device (1): Tesla T4, Compute Capability 7.5\nI0000 00:00:1745525474.221910     343 cuda_dnn.cc:529] Loaded cuDNN version 90300\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m117/216\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0977 - loss: 3.2584  ","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1745525475.832746     343 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 0.1414 - loss: 3.0983 - val_accuracy: 0.5163 - val_loss: 1.9486\nEpoch 2/20\n\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4274 - loss: 1.9911 - val_accuracy: 0.6446 - val_loss: 1.3322\nEpoch 3/20\n\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5600 - loss: 1.5109 - val_accuracy: 0.7276 - val_loss: 1.0396\nEpoch 4/20\n\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6384 - loss: 1.2350 - val_accuracy: 0.7387 - val_loss: 0.9387\nEpoch 5/20\n\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6927 - loss: 1.0442 - val_accuracy: 0.7758 - val_loss: 0.8072\nEpoch 6/20\n\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7323 - loss: 0.8942 - val_accuracy: 0.7695 - val_loss: 0.7998\nEpoch 7/20\n\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7408 - loss: 0.8586 - val_accuracy: 0.7811 - val_loss: 0.7400\nEpoch 8/20\n\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7502 - loss: 0.8231 - val_accuracy: 0.7933 - val_loss: 0.6803\nEpoch 9/20\n\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7673 - loss: 0.7383 - val_accuracy: 0.8055 - val_loss: 0.6547\nEpoch 10/20\n\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7829 - loss: 0.6849 - val_accuracy: 0.8159 - val_loss: 0.6096\nEpoch 11/20\n\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7953 - loss: 0.6624 - val_accuracy: 0.7979 - val_loss: 0.6371\nEpoch 12/20\n\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8131 - loss: 0.6133 - val_accuracy: 0.8182 - val_loss: 0.5859\nEpoch 13/20\n\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8008 - loss: 0.6237 - val_accuracy: 0.8188 - val_loss: 0.6334\nEpoch 14/20\n\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8103 - loss: 0.6042 - val_accuracy: 0.8200 - val_loss: 0.5751\nEpoch 15/20\n\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8211 - loss: 0.5590 - val_accuracy: 0.8142 - val_loss: 0.6094\nEpoch 16/20\n\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8166 - loss: 0.5589 - val_accuracy: 0.8275 - val_loss: 0.5766\nEpoch 17/20\n\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8210 - loss: 0.5602 - val_accuracy: 0.8269 - val_loss: 0.5610\nEpoch 18/20\n\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8366 - loss: 0.4956 - val_accuracy: 0.8386 - val_loss: 0.5565\nEpoch 19/20\n\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8544 - loss: 0.4583 - val_accuracy: 0.8345 - val_loss: 0.5515\nEpoch 20/20\n\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8350 - loss: 0.4884 - val_accuracy: 0.8333 - val_loss: 0.5807\n\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n              precision    recall  f1-score   support\n\n           0     0.9467    0.9595    0.9530        74\n           1     0.9487    1.0000    0.9737        74\n           2     0.9286    0.8784    0.9028        74\n           3     0.9333    0.5676    0.7059        74\n           4     0.7416    0.8919    0.8098        74\n           5     0.7079    0.8514    0.7730        74\n           6     0.9865    0.9733    0.9799        75\n           7     0.8391    0.9733    0.9012        75\n           8     1.0000    1.0000    1.0000        74\n           9     0.8462    0.7432    0.7914        74\n          10     0.8824    1.0000    0.9375        75\n          11     0.7347    0.4865    0.5854        74\n          12     0.6829    0.7568    0.7179        74\n          13     1.0000    1.0000    1.0000        74\n          14     0.7750    0.8267    0.8000        75\n          15     0.9865    0.9865    0.9865        74\n          16     0.7632    0.7838    0.7733        74\n          17     0.5283    0.3784    0.4409        74\n          18     0.7500    0.7297    0.7397        74\n          19     0.9636    0.7067    0.8154        75\n          20     0.5571    0.5200    0.5379        75\n          21     0.8750    0.6622    0.7538        74\n          22     0.8506    1.0000    0.9193        74\n          23     0.7660    0.9730    0.8571        74\n          24     0.9125    0.9865    0.9481        74\n          25     0.9136    1.0000    0.9548        74\n          26     0.9487    1.0000    0.9737        74\n          27     0.9610    1.0000    0.9801        74\n          28     0.5783    0.6486    0.6115        74\n\n    accuracy                         0.8374      2152\n   macro avg     0.8382    0.8374    0.8319      2152\nweighted avg     0.8382    0.8374    0.8318      2152\n\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"from transformers import BertTokenizer\nimport pickle\n\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\nwith open('bert_tokenizer.pkl', 'wb') as f:\n    pickle.dump(tokenizer, f)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T20:15:24.309807Z","iopub.execute_input":"2025-04-24T20:15:24.311055Z","iopub.status.idle":"2025-04-24T20:15:24.456352Z","shell.execute_reply.started":"2025-04-24T20:15:24.311025Z","shell.execute_reply":"2025-04-24T20:15:24.455585Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nimport pickle\n\nwith open('label_encoder.pkl', 'wb') as f:\n    pickle.dump(label_encoder, f)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T20:15:52.891417Z","iopub.execute_input":"2025-04-24T20:15:52.891931Z","iopub.status.idle":"2025-04-24T20:15:52.896367Z","shell.execute_reply.started":"2025-04-24T20:15:52.891904Z","shell.execute_reply":"2025-04-24T20:15:52.895581Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"model.save('bert_ffnn_model.h5')  # You can later load it with keras.models.load_model()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T20:16:03.582507Z","iopub.execute_input":"2025-04-24T20:16:03.582768Z","iopub.status.idle":"2025-04-24T20:16:03.622380Z","shell.execute_reply.started":"2025-04-24T20:16:03.582752Z","shell.execute_reply":"2025-04-24T20:16:03.621822Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"import numpy as np\n\nnp.save('X_train_bert.npy', X_train_bert)\nnp.save('X_test_bert.npy', X_test_bert)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T20:18:38.454883Z","iopub.execute_input":"2025-04-24T20:18:38.455631Z","iopub.status.idle":"2025-04-24T20:18:38.482122Z","shell.execute_reply.started":"2025-04-24T20:18:38.455606Z","shell.execute_reply":"2025-04-24T20:18:38.481572Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}