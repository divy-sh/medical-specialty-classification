{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "31kgUE4KFLfe",
        "outputId": "ef2e5820-46ed-468f-c39f-0808d9806785",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kagglehub in /usr/local/lib/python3.11/dist-packages (0.3.11)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from kagglehub) (24.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from kagglehub) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kagglehub) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from kagglehub) (4.67.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub) (2025.1.31)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n",
            "Collecting sklearn\n",
            "  Downloading sklearn-0.0.post12.tar.gz (2.6 kB)\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
            "\u001b[1;36mhint\u001b[0m: See above for details.\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.13.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.71.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.14.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: tf-keras in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: tensorflow<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tf-keras) (2.18.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (5.29.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (3.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (4.13.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (1.71.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow<2.19,>=2.18->tf-keras) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow<2.19,>=2.18->tf-keras) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow<2.19,>=2.18->tf-keras) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow<2.19,>=2.18->tf-keras) (0.14.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow<2.19,>=2.18->tf-keras) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow<2.19,>=2.18->tf-keras) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow<2.19,>=2.18->tf-keras) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow<2.19,>=2.18->tf-keras) (2025.1.31)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18->tf-keras) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18->tf-keras) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18->tf-keras) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18->tf-keras) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow<2.19,>=2.18->tf-keras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow<2.19,>=2.18->tf-keras) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow<2.19,>=2.18->tf-keras) (0.1.2)\n",
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.11/dist-packages (0.13.0)\n",
            "Requirement already satisfied: numpy<3,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (2.0.2)\n",
            "Requirement already satisfied: scipy<2,>=1.10.1 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (1.14.1)\n",
            "Requirement already satisfied: scikit-learn<2,>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (1.6.1)\n",
            "Requirement already satisfied: sklearn-compat<1,>=0.1 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (0.1.3)\n",
            "Requirement already satisfied: joblib<2,>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl<4,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (3.6.0)\n"
          ]
        }
      ],
      "source": [
        "%pip install kagglehub\n",
        "%pip install pandas\n",
        "%pip install nltk\n",
        "%pip install sklearn\n",
        "%pip install tensorflow\n",
        "%pip install matplotlib\n",
        "%pip install tf-keras\n",
        "%pip install imbalanced-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gQLHDLkJFLfg",
        "outputId": "dcc359cc-8bf7-4132-9160-3d479511df88"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import kagglehub\n",
        "import pandas as pd\n",
        "import regex as re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('wordnet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fMwqXukyFLfg",
        "outputId": "2396f841-a2b7-420e-ca05-9c043f6879dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Head:  <bound method NDFrame.head of       Unnamed: 0                                        description  \\\n",
            "0              0   A 23-year-old white female presents with comp...   \n",
            "1              1           Consult for laparoscopic gastric bypass.   \n",
            "2              2           Consult for laparoscopic gastric bypass.   \n",
            "3              3                             2-D M-Mode. Doppler.     \n",
            "4              4                                 2-D Echocardiogram   \n",
            "...          ...                                                ...   \n",
            "4994        4994   Patient having severe sinusitis about two to ...   \n",
            "4995        4995   This is a 14-month-old baby boy Caucasian who...   \n",
            "4996        4996   A female for a complete physical and follow u...   \n",
            "4997        4997   Mother states he has been wheezing and coughing.   \n",
            "4998        4998   Acute allergic reaction, etiology uncertain, ...   \n",
            "\n",
            "                medical_specialty                                sample_name  \\\n",
            "0            Allergy / Immunology                         Allergic Rhinitis    \n",
            "1                      Bariatrics   Laparoscopic Gastric Bypass Consult - 2    \n",
            "2                      Bariatrics   Laparoscopic Gastric Bypass Consult - 1    \n",
            "3      Cardiovascular / Pulmonary                    2-D Echocardiogram - 1    \n",
            "4      Cardiovascular / Pulmonary                    2-D Echocardiogram - 2    \n",
            "...                           ...                                        ...   \n",
            "4994         Allergy / Immunology                         Chronic Sinusitis    \n",
            "4995         Allergy / Immunology      Kawasaki Disease - Discharge Summary    \n",
            "4996         Allergy / Immunology                        Followup on Asthma    \n",
            "4997         Allergy / Immunology                    Asthma in a 5-year-old    \n",
            "4998         Allergy / Immunology                Allergy Evaluation Consult    \n",
            "\n",
            "                                          transcription  \\\n",
            "0     SUBJECTIVE:,  This 23-year-old white female pr...   \n",
            "1     PAST MEDICAL HISTORY:, He has difficulty climb...   \n",
            "2     HISTORY OF PRESENT ILLNESS: , I have seen ABC ...   \n",
            "3     2-D M-MODE: , ,1.  Left atrial enlargement wit...   \n",
            "4     1.  The left ventricular cavity size and wall ...   \n",
            "...                                                 ...   \n",
            "4994  HISTORY:,  I had the pleasure of meeting and e...   \n",
            "4995  ADMITTING DIAGNOSIS: , Kawasaki disease.,DISCH...   \n",
            "4996  SUBJECTIVE: , This is a 42-year-old white fema...   \n",
            "4997  CHIEF COMPLAINT: , This 5-year-old male presen...   \n",
            "4998  HISTORY: , A 34-year-old male presents today s...   \n",
            "\n",
            "                                               keywords  \n",
            "0     allergy / immunology, allergic rhinitis, aller...  \n",
            "1     bariatrics, laparoscopic gastric bypass, weigh...  \n",
            "2     bariatrics, laparoscopic gastric bypass, heart...  \n",
            "3     cardiovascular / pulmonary, 2-d m-mode, dopple...  \n",
            "4     cardiovascular / pulmonary, 2-d, doppler, echo...  \n",
            "...                                                 ...  \n",
            "4994                                                NaN  \n",
            "4995  allergy / immunology, mucous membranes, conjun...  \n",
            "4996                                                NaN  \n",
            "4997                                                NaN  \n",
            "4998                                                NaN  \n",
            "\n",
            "[4999 rows x 6 columns]>\n"
          ]
        }
      ],
      "source": [
        "dataset = pd.read_csv(\"/content/mtsamples.csv\")\n",
        "print(\"Head: \", dataset.head)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZgaYplIzFLfh"
      },
      "source": [
        "## Data processing\n",
        "\n",
        "- We drop every other column except transcription and medical_specialty.\n",
        "- We also drop any rows with empty or null transcription or medical_specialty.\n",
        "\n",
        "- Then we drop all the classes in the excluded specialties list below. We do this as these are general terms and don't specifically map to any specialty.\n",
        "- We then merge the classes with large overlaps - e.g. Neurosurgery and neurology, Neurosurgery is a subset of neurology."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "btKFXrJNFLfm",
        "outputId": "6816b43d-d497-4fab-8034-91f61ff0cf8b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Category 0: Cardiovascular / Pulmonary: 371\n",
            "Category 1: ENT - Otolaryngology: 96\n",
            "Category 2: Gastroenterology: 224\n",
            "Category 3: Hematology - Oncology: 90\n",
            "Category 4: Neurology: 317\n",
            "Category 5: Obstetrics / Gynecology: 155\n",
            "Category 6: Ophthalmology: 83\n",
            "Category 7: Orthopedic: 355\n",
            "Category 8: Pediatrics - Neonatal: 70\n",
            "Category 9: Podiatry: 47\n",
            "Category 10: Psychiatry / Psychology: 53\n",
            "Category 11: Urology: 237\n"
          ]
        }
      ],
      "source": [
        "\n",
        "dataset.dropna(subset=['transcription', 'medical_specialty'], inplace=True)\n",
        "\n",
        "dataset = dataset[['transcription', 'medical_specialty']]\n",
        "\n",
        "specialty_counts = dataset['medical_specialty'].value_counts()\n",
        "valid_specialties = specialty_counts[specialty_counts >= 30].index\n",
        "dataset = dataset[dataset['medical_specialty'].isin(valid_specialties)]\n",
        "\n",
        "dataset['medical_specialty'] = dataset['medical_specialty'].str.strip()\n",
        "\n",
        "excluded_specialties = [\n",
        "    'Surgery',\n",
        "    'SOAP / Chart / Progress Notes',\n",
        "    'Office Notes',\n",
        "    'Consult - History and Phy.',\n",
        "    'Emergency Room Reports',\n",
        "    'Discharge Summary',\n",
        "    'Pain Management',\n",
        "    'General Medicine',\n",
        "    'Radiology',\n",
        "]\n",
        "\n",
        "dataset = dataset[~dataset['medical_specialty'].isin(excluded_specialties)]\n",
        "\n",
        "category_mapping = {\n",
        "    'Neurosurgery': 'Neurology',\n",
        "    'Nephrology': 'Urology',\n",
        "}\n",
        "\n",
        "dataset['medical_specialty'] = dataset['medical_specialty'].replace(category_mapping)\n",
        "\n",
        "for i, (category_name, category) in enumerate(dataset.groupby(\"medical_specialty\")):\n",
        "    print(f\"Category {i}: {category_name}: {len(category)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FvAv-4CwFLfm"
      },
      "source": [
        "## Data processing\n",
        "\n",
        "- We clean the text and then tokenize it and then lemmatize all the words in it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "HkR5m-76FLfm"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def clean_text(text):\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    text = text.strip()\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
        "    text = \" \".join([lemmatizer.lemmatize(word) for word in word_tokenize(text) if word not in stopwords.words('english')])\n",
        "    return text\n",
        "\n",
        "dataset['processed_transcription'] = dataset['transcription'].apply(clean_text)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    dataset['processed_transcription'], dataset['medical_specialty'], test_size=0.2, random_state=42, stratify=dataset['medical_specialty']\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LSTM"
      ],
      "metadata": {
        "id": "GDLXivWw0cZ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, GlobalMaxPooling1D\n",
        "\n",
        "\n",
        "embedding_dim = 128\n",
        "lstm_units = 64\n",
        "max_len = 256\n",
        "max_words = 50000\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "y_train_encoded = label_encoder.fit_transform(y_train)\n",
        "y_test_encoded = label_encoder.transform(y_test)\n",
        "\n",
        "tokenizer = Tokenizer(num_words=max_words)\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "X_train_sequences = tokenizer.texts_to_sequences(X_train)\n",
        "X_test_sequences = tokenizer.texts_to_sequences(X_test)\n",
        "\n",
        "X_train_padded = pad_sequences(X_train_sequences, maxlen=max_len)\n",
        "X_test_padded = pad_sequences(X_test_sequences, maxlen=max_len)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=max_words, output_dim=embedding_dim, input_length=max_len))\n",
        "\n",
        "model.add(LSTM(128, return_sequences=True))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(LSTM(64))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(len(set(y_train)), activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(X_train_padded, to_categorical(y_train_encoded), epochs=40, batch_size=32, validation_split=0.2)\n",
        "\n",
        "y_pred_probs = model.predict(X_test_padded)\n",
        "y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "y_true = y_test_encoded\n",
        "\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_true, y_pred, digits=4))\n",
        "\n",
        "precision = precision_score(y_true, y_pred, average='weighted')\n",
        "recall = recall_score(y_true, y_pred, average='weighted')\n",
        "f1 = f1_score(y_true, y_pred, average='weighted')\n",
        "accuracy = accuracy_score(y_true, y_pred)\n",
        "\n",
        "print(f\"Accuracy:  {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall:    {recall:.4f}\")\n",
        "print(f\"F1 Score:  {f1:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BeawqXHD0cKL",
        "outputId": "c4cda907-b502-48d3-c649-03af374a5fb0"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 37ms/step - accuracy: 0.1656 - loss: 2.4166 - val_accuracy: 0.1994 - val_loss: 2.2811\n",
            "Epoch 2/40\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.2088 - loss: 2.1339 - val_accuracy: 0.2679 - val_loss: 2.0179\n",
            "Epoch 3/40\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.3715 - loss: 1.7173 - val_accuracy: 0.4435 - val_loss: 1.7164\n",
            "Epoch 4/40\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.5790 - loss: 1.3090 - val_accuracy: 0.4167 - val_loss: 1.7428\n",
            "Epoch 5/40\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.7158 - loss: 0.8990 - val_accuracy: 0.4702 - val_loss: 1.7377\n",
            "Epoch 6/40\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.7330 - loss: 0.8321 - val_accuracy: 0.4911 - val_loss: 1.8271\n",
            "Epoch 7/40\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.7997 - loss: 0.6549 - val_accuracy: 0.4970 - val_loss: 1.8357\n",
            "Epoch 8/40\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.8051 - loss: 0.5705 - val_accuracy: 0.4970 - val_loss: 1.8802\n",
            "Epoch 9/40\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.8462 - loss: 0.4826 - val_accuracy: 0.4970 - val_loss: 1.9122\n",
            "Epoch 10/40\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.8637 - loss: 0.4482 - val_accuracy: 0.4643 - val_loss: 1.9606\n",
            "Epoch 11/40\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.8593 - loss: 0.4297 - val_accuracy: 0.4821 - val_loss: 1.9756\n",
            "Epoch 12/40\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.8830 - loss: 0.3306 - val_accuracy: 0.4673 - val_loss: 2.1885\n",
            "Epoch 13/40\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - accuracy: 0.8962 - loss: 0.3362 - val_accuracy: 0.4435 - val_loss: 2.0797\n",
            "Epoch 14/40\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.8955 - loss: 0.3362 - val_accuracy: 0.4940 - val_loss: 2.0456\n",
            "Epoch 15/40\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.9065 - loss: 0.2997 - val_accuracy: 0.5000 - val_loss: 2.2033\n",
            "Epoch 16/40\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.8956 - loss: 0.2869 - val_accuracy: 0.5060 - val_loss: 2.1033\n",
            "Epoch 17/40\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.9149 - loss: 0.2457 - val_accuracy: 0.5089 - val_loss: 2.2482\n",
            "Epoch 18/40\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.9078 - loss: 0.2488 - val_accuracy: 0.5179 - val_loss: 2.2723\n",
            "Epoch 19/40\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.9322 - loss: 0.1992 - val_accuracy: 0.5238 - val_loss: 2.3003\n",
            "Epoch 20/40\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.9104 - loss: 0.2187 - val_accuracy: 0.5060 - val_loss: 2.2581\n",
            "Epoch 21/40\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.9150 - loss: 0.2008 - val_accuracy: 0.5030 - val_loss: 2.4224\n",
            "Epoch 22/40\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.9061 - loss: 0.2234 - val_accuracy: 0.4613 - val_loss: 2.3688\n",
            "Epoch 23/40\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.8941 - loss: 0.2536 - val_accuracy: 0.5030 - val_loss: 2.4562\n",
            "Epoch 24/40\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.9176 - loss: 0.2043 - val_accuracy: 0.4940 - val_loss: 2.4803\n",
            "Epoch 25/40\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.9182 - loss: 0.1812 - val_accuracy: 0.4911 - val_loss: 2.4740\n",
            "Epoch 26/40\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.9168 - loss: 0.2011 - val_accuracy: 0.5060 - val_loss: 2.5491\n",
            "Epoch 27/40\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.9256 - loss: 0.1871 - val_accuracy: 0.5179 - val_loss: 2.6727\n",
            "Epoch 28/40\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.9316 - loss: 0.1640 - val_accuracy: 0.5060 - val_loss: 2.6936\n",
            "Epoch 29/40\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.8991 - loss: 0.2254 - val_accuracy: 0.4702 - val_loss: 2.8359\n",
            "Epoch 30/40\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.9187 - loss: 0.1780 - val_accuracy: 0.4821 - val_loss: 2.5763\n",
            "Epoch 31/40\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.9108 - loss: 0.2077 - val_accuracy: 0.4970 - val_loss: 2.7794\n",
            "Epoch 32/40\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.9244 - loss: 0.1741 - val_accuracy: 0.4940 - val_loss: 2.8620\n",
            "Epoch 33/40\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.8915 - loss: 0.1932 - val_accuracy: 0.5060 - val_loss: 2.8812\n",
            "Epoch 34/40\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.9254 - loss: 0.1474 - val_accuracy: 0.4940 - val_loss: 2.8213\n",
            "Epoch 35/40\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.9225 - loss: 0.1595 - val_accuracy: 0.5089 - val_loss: 2.8576\n",
            "Epoch 36/40\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.9052 - loss: 0.1968 - val_accuracy: 0.5149 - val_loss: 2.8341\n",
            "Epoch 37/40\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.9014 - loss: 0.1718 - val_accuracy: 0.5060 - val_loss: 2.9221\n",
            "Epoch 38/40\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.9080 - loss: 0.1740 - val_accuracy: 0.4762 - val_loss: 2.9363\n",
            "Epoch 39/40\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.9138 - loss: 0.1861 - val_accuracy: 0.4911 - val_loss: 2.9629\n",
            "Epoch 40/40\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - accuracy: 0.9247 - loss: 0.1472 - val_accuracy: 0.4851 - val_loss: 2.9812\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.7231    0.6351    0.6763        74\n",
            "           1     0.6429    0.4737    0.5455        19\n",
            "           2     0.6000    0.6000    0.6000        45\n",
            "           3     0.1481    0.2222    0.1778        18\n",
            "           4     0.5079    0.5000    0.5039        64\n",
            "           5     0.6053    0.7419    0.6667        31\n",
            "           6     0.8571    0.7059    0.7742        17\n",
            "           7     0.5119    0.6056    0.5548        71\n",
            "           8     0.3077    0.2857    0.2963        14\n",
            "           9     0.2500    0.2222    0.2353         9\n",
            "          10     0.3333    0.2727    0.3000        11\n",
            "          11     0.6000    0.5106    0.5517        47\n",
            "\n",
            "    accuracy                         0.5476       420\n",
            "   macro avg     0.5073    0.4813    0.4902       420\n",
            "weighted avg     0.5619    0.5476    0.5514       420\n",
            "\n",
            "Accuracy:  0.5476\n",
            "Precision: 0.5619\n",
            "Recall:    0.5476\n",
            "F1 Score:  0.5514\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "BERT embedding"
      ],
      "metadata": {
        "id": "EEDueomYJ6HN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import BertTokenizer, BertModel\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "bert = BertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "def get_bert_embeddings(texts):\n",
        "    embeddings = []\n",
        "    for text in tqdm(texts):\n",
        "        inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=256)\n",
        "        with torch.no_grad():\n",
        "            outputs = bert(**inputs)\n",
        "        cls_embedding = outputs.last_hidden_state[:, 0, :].squeeze().numpy()\n",
        "        embeddings.append(cls_embedding)\n",
        "    return np.array(embeddings)\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "y_encoded = label_encoder.fit_transform(y_train)\n",
        "\n",
        "X_train_bert = get_bert_embeddings(X_train)\n",
        "X_test_bert = get_bert_embeddings(X_test)\n",
        "\n",
        "y_train_cat = to_categorical(y_encoded)\n",
        "y_test_encoded_cat = label_encoder.transform(y_test)\n",
        "y_test_cat = to_categorical(y_test_encoded_cat)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(256, activation='relu', input_shape=(768,)))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(len(label_encoder.classes_), activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "model.fit(X_train_bert, y_train_cat, epochs=20, batch_size=32, validation_split=0.2)\n",
        "\n",
        "y_pred_probs = model.predict(X_test_bert)\n",
        "y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test_encoded_cat, y_pred, digits=4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VHoIpmGXJ56z",
        "outputId": "67295e22-9c5f-4013-9f18-d3f877a85579"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1678/1678 [12:24<00:00,  2.25it/s]\n",
            "100%|██████████| 420/420 [03:09<00:00,  2.22it/s]\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 81ms/step - accuracy: 0.1722 - loss: 2.3542 - val_accuracy: 0.2232 - val_loss: 2.1914\n",
            "Epoch 2/20\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2916 - loss: 2.1482 - val_accuracy: 0.3036 - val_loss: 2.0525\n",
            "Epoch 3/20\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3029 - loss: 2.0089 - val_accuracy: 0.3363 - val_loss: 1.8502\n",
            "Epoch 4/20\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3974 - loss: 1.7995 - val_accuracy: 0.4464 - val_loss: 1.6781\n",
            "Epoch 5/20\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4284 - loss: 1.6910 - val_accuracy: 0.4613 - val_loss: 1.6167\n",
            "Epoch 6/20\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4965 - loss: 1.5148 - val_accuracy: 0.4583 - val_loss: 1.5593\n",
            "Epoch 7/20\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4902 - loss: 1.5167 - val_accuracy: 0.5119 - val_loss: 1.4692\n",
            "Epoch 8/20\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5199 - loss: 1.3750 - val_accuracy: 0.5476 - val_loss: 1.4169\n",
            "Epoch 9/20\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5720 - loss: 1.2922 - val_accuracy: 0.5089 - val_loss: 1.4626\n",
            "Epoch 10/20\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5640 - loss: 1.2371 - val_accuracy: 0.4970 - val_loss: 1.4329\n",
            "Epoch 11/20\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5836 - loss: 1.1875 - val_accuracy: 0.5446 - val_loss: 1.3562\n",
            "Epoch 12/20\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6029 - loss: 1.1022 - val_accuracy: 0.5714 - val_loss: 1.3306\n",
            "Epoch 13/20\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6389 - loss: 1.0797 - val_accuracy: 0.5298 - val_loss: 1.3447\n",
            "Epoch 14/20\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6192 - loss: 1.0906 - val_accuracy: 0.5357 - val_loss: 1.3297\n",
            "Epoch 15/20\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6529 - loss: 1.0038 - val_accuracy: 0.5744 - val_loss: 1.2609\n",
            "Epoch 16/20\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6667 - loss: 0.9792 - val_accuracy: 0.5923 - val_loss: 1.2822\n",
            "Epoch 17/20\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7155 - loss: 0.8594 - val_accuracy: 0.5357 - val_loss: 1.4012\n",
            "Epoch 18/20\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6566 - loss: 0.9320 - val_accuracy: 0.5774 - val_loss: 1.3591\n",
            "Epoch 19/20\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6835 - loss: 0.8707 - val_accuracy: 0.5387 - val_loss: 1.3897\n",
            "Epoch 20/20\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6798 - loss: 0.9111 - val_accuracy: 0.5655 - val_loss: 1.2862\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.7344    0.6351    0.6812        74\n",
            "           1     0.8333    0.5263    0.6452        19\n",
            "           2     0.5789    0.4889    0.5301        45\n",
            "           3     0.1875    0.3333    0.2400        18\n",
            "           4     0.5714    0.6875    0.6241        64\n",
            "           5     0.6071    0.5484    0.5763        31\n",
            "           6     0.6500    0.7647    0.7027        17\n",
            "           7     0.6456    0.7183    0.6800        71\n",
            "           8     0.5000    0.5714    0.5333        14\n",
            "           9     1.0000    0.1111    0.2000         9\n",
            "          10     1.0000    0.7273    0.8421        11\n",
            "          11     0.6000    0.5745    0.5870        47\n",
            "\n",
            "    accuracy                         0.6048       420\n",
            "   macro avg     0.6590    0.5572    0.5702       420\n",
            "weighted avg     0.6359    0.6048    0.6071       420\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}